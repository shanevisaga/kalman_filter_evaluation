{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5f7eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code makes diagnostic plots for raw and postprocessed WRF-Solar output\n",
    "Postprocessing using the Kalman Filter is from Rafael Alvarenga's code (rafael.alvarenga@etu.univ-guyane.fr)\n",
    "\"\"\"\n",
    "\n",
    "from file_func import *\n",
    "from __const__ import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "655c7957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Time', 'CMP22_Total_Solar', 'SPN1_Total_Solar',\n",
       "       'SPN1_Diff_Solar', 'CGR4_IR', 'dhi', 'ghi_a', 'sza', 'cossza', 'dni',\n",
       "       'MM', 'DD', 'HH', 'mm', 'GHI_in', 'DNI_in', 'DHI_in', 'cossza_b',\n",
       "       'SPN1_Total_Solar_N', 't2_lim', 'cossza_noon', 'FT_t', 'FT_TOA',\n",
       "       'FT_TOA_t', 't3_llim', 't3_ulim', 'Diffuse_Ratio', 'SPN1_Diff_Solar_N',\n",
       "       'sigma', 'ghi_cc_val', 'dhi_cc_val', 't1_lim', 'flag_clear', 'ghi_obs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.read_csv('with_flags.csv')\n",
    "a['Time'] = pd.to_datetime(a['Time'])\n",
    "\n",
    "a['ghi_obs'] = a['SPN1_Total_Solar']\n",
    "a.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b688d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'/Users/apple/Desktop/Others/Python_Codes/wrf_solar/csv_{year}_runs/' # use your path\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "mod_ = []\n",
    "\n",
    "for f in all_files:\n",
    "    mod = pd.read_csv(f)\n",
    "    mod['Time'] = pd.to_datetime(mod['time'])#.dt.tz_localize(tz)\n",
    "    mod = mod.set_index('Time')\n",
    "    t0 = mod.index[0] + datetime.timedelta(hours=21)\n",
    "    tf = t0 + datetime.timedelta(hours=14)\n",
    "    mod['plot'] = 'N'\n",
    "    mod.loc[((mod.index >= t0) & (mod.index<= tf)), 'plot'] = 'Y'\n",
    "    mod=mod[mod['plot']=='Y']\n",
    "    mod = mod.reset_index()\n",
    "    mod_.append(mod)\n",
    "    \n",
    "mod_ = pd.concat(mod_)\n",
    "mod_ = mod_[['Time', 'ens', 'ghi', 'swddni', 'coszen', 'swddif', 'lon', 'lat', 'hour', 'station_name',\n",
    "       'domain']]\n",
    "mod_ = pd.melt(mod_, id_vars=['Time', 'ens', 'domain', 'station_name'], value_vars=['ghi'] ,value_name='ghi_mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f2a89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(main_dir_path_recursive, exist_ok=True)\n",
    "\n",
    "\n",
    "df = prep_opt(mod_, a)[0]\n",
    "df_temp = prep_opt(mod_, a)[1]\n",
    "\n",
    "nb_LTs = len(np.unique(df_temp.LT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd21440",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1446/1446 [00:31<00:00, 45.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************\n",
      "Predictors: ['Kc_GHI_pred', 'cossza']\n",
      "- RMS: 234.46576645986988\n",
      "- MAE: 178.78001047938008\n",
      "- MBE: 0.23886633198908014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/Desktop/Others/Python_Codes/wrf_solar/file_func.py:256: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"frameon\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  plt.savefig(f\"{dir_path_recursive}/{year}_{nb_historical_days}_all_kf_Manila_ts_\" + str(res) +\"km.png\", dpi=500, frameon=False, facecolor='white', bbox_inches=\"tight\")\n",
      "/Users/apple/Desktop/Others/Python_Codes/wrf_solar/file_func.py:464: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"frameon\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  plt.savefig(f\"{dir_path_recursive}/{year}_{nb_historical_days}_all_cloudy_kf_Manila_scatplot_\" + str((res)) + \"km.png\", dpi=500, frameon=False, facecolor='white', bbox_inches=\"tight\")\n",
      "/Users/apple/Desktop/Others/Python_Codes/wrf_solar/file_func.py:581: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"frameon\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  plt.savefig(f\"{dir_path_recursive}/{year}_{nb_historical_days}_all_clear_kf_Manila_scatplot_\" + str((res)) + \"km.png\", dpi=500, frameon=False, facecolor='white', bbox_inches=\"tight\")\n",
      " 29%|███████████▌                            | 417/1446 [00:24<01:50,  9.30it/s]"
     ]
    }
   ],
   "source": [
    "for nb_historical_days in [3,11]:\n",
    "    #nb_historical_days = 11\n",
    "    timestep_enough_historical = (nb_historical_days*2)*nb_LTs  \n",
    "    for t in tqdm(range(len(df_temp))):\n",
    "\n",
    "        hour = df_temp.loc[t,'Time'].hour\n",
    "        minutes = df_temp.loc[t,'Time'].minute\n",
    "        #print(f'Time: {lt_hours}:{lt_minutes:02d} (+{lt})')\n",
    "\n",
    "\n",
    "        if t >= timestep_enough_historical:\n",
    "            # slice df\n",
    "            df_timestep = df_temp.loc[t-(nb_historical_days*nb_LTs)-(nb_historical_days*nb_LTs*recursive_calculation_covariance_matrices):t,:].copy()\n",
    "        else:\n",
    "            df_timestep = df_temp.loc[t:t+(nb_historical_days*nb_LTs)+(nb_historical_days*nb_LTs*recursive_calculation_covariance_matrices),:].copy()\n",
    "            df_timestep = df_timestep[::-1].reset_index(drop=True)\n",
    "        df_timestep = df_timestep.loc[(df_timestep['Time'].dt.hour == hour) & (df_timestep['Time'].dt.minute == minutes)]\n",
    "        df_timestep = df_timestep.loc[~np.isnan(df_timestep['Kc_GHI_pred'])]\n",
    "        df_timestep = df_timestep.loc[~np.isnan(df_timestep['Kc_obs_bias'])]\n",
    "\n",
    "        if (len(df_timestep) == 0) & (len(df_timestep) <= nb_historical_days + (nb_historical_days*recursive_calculation_covariance_matrices) or (t not in df_timestep.index)):\n",
    "            df_temp.loc[t,'Kc_GHI_pred_improved'] = np.nan  \n",
    "            continue\n",
    "\n",
    "        df_timestep = df_timestep.iloc[-(nb_historical_days+1)-(nb_historical_days*recursive_calculation_covariance_matrices):,:]\n",
    "        df_timestep = df_timestep.reset_index(drop = True)\n",
    "\n",
    "        # define prediction-bias variance matrix\n",
    "        W = np.eye(len(predictors_vector))/1000\n",
    "\n",
    "        # define measurement-bias variance matrix\n",
    "        V = 0.01\n",
    "\n",
    "        # define initial error covariance matrix\n",
    "        Po = np.eye(len(predictors_vector))*5\n",
    "\n",
    "        # define initial predicted bias\n",
    "        xo = np.zeros(len(predictors_vector)).reshape(len(predictors_vector),1)\n",
    "\n",
    "        measurement_GHI = []\n",
    "        old_predicted_GHI = []\n",
    "        improved_GHI = []\n",
    "        ground_truths = []\n",
    "        predicted_coefs = []\n",
    "\n",
    "        for idx_i, i in enumerate(df_timestep.index):\n",
    "            if recursive_calculation_covariance_matrices == True:\n",
    "                # --------------------------------------------\n",
    "                #  Calculate matrices of covariance of errors\n",
    "                # --------------------------------------------\n",
    "                if idx_i > nb_historical_days:\n",
    "                    mean_w = sum(predicted_coefs[-(1+day)] - predicted_coefs[-(2+day)] for day in range(nb_historical_days))/nb_historical_days\n",
    "                    mean_v = sum(measurement_GHI[-(1+day)] - improved_GHI[-(1+day)] for day in range(nb_historical_days))/nb_historical_days\n",
    "\n",
    "                    # old method\n",
    "                    W = np.diag(list((1/(nb_historical_days-1))*sum(((predicted_coefs[-(1+day)] - predicted_coefs[-(2+day)]) - mean_w)**2 for day in range(nb_historical_days)).reshape(len(predictors_vector),)))\n",
    "                    V = (1/(nb_historical_days-1))*sum(((measurement_GHI[-(1+day)] - improved_GHI[-(1+day)]) - mean_v)**2 for day in range(nb_historical_days))\n",
    "\n",
    "                    # # improved method (from Lynch, 2014 - Simplified method to derive the Kalman Filter covariance matrices to predict wind speeds from a NWP model)\n",
    "                    # W = (1/(nb_historical_days-1))*sum(dot(((predicted_coefs[-(1+day)] - predicted_coefs[-(2+day)]) - mean_w),((predicted_coefs[-(1+day)] - predicted_coefs[-(2+day)]) - mean_w).T) for day in range(nb_historical_days))\n",
    "                    # V = (1/(nb_historical_days-1))*sum(dot(((measurement_GHI[-(1+day)] - improved_GHI[-(1+day)]) - mean_v),((measurement_GHI[-(1+day)] - improved_GHI[-(1+day)]) - mean_v).T) for day in range(nb_historical_days))\n",
    "\n",
    "            # ----------------------------\n",
    "            #           Predict\n",
    "            # ----------------------------\n",
    "\n",
    "            if idx_i == 0:\n",
    "                # predicted mean bias\n",
    "                x_pred = np.zeros_like(xo)\n",
    "                if add_noise_in_predictions == True:\n",
    "                    x_pred = xo + np.random.multivariate_normal(mean=[0.5]*len(predictors_vector), cov=W, size=1).reshape(-1,1)\n",
    "                else:\n",
    "                    x_pred = xo\n",
    "\n",
    "                # predicted bias covariance matrix\n",
    "                P = Po + W\n",
    "\n",
    "            else:\n",
    "                # predicted mean bias\n",
    "                if add_noise_in_predictions == True:\n",
    "                    x_pred = x_pred + np.random.multivariate_normal(mean=[0]*len(predictors_vector), cov=W, size=1).reshape(-1,1)\n",
    "                else:\n",
    "                    x_pred = x_pred\n",
    "                #x_pred[1:,0] = 0 # only bias is being tracked, our prediction model doesn't account for the other predictors\n",
    "\n",
    "                # predicted bias covariance matrix\n",
    "                P = P + W\n",
    "\n",
    "            # ----------------------------\n",
    "            #           Update\n",
    "            # ----------------------------\n",
    "\n",
    "            # compute transition matrix based on the current predictors for this timestep\n",
    "            H = [df_timestep.loc[i,predictor] for predictor in predictors_vector[1:]]\n",
    "            H = np.asarray([1] + H).reshape(1, len(predictors_vector))\n",
    "            if nonlinear_predictions == True:\n",
    "                H = [predictor**idx_predictor for idx_predictor, predictor in enumerate(H)]\n",
    "\n",
    "            predicted_coefs.append(x_pred)\n",
    "            improved_GHI.append(dot(H,x_pred))\n",
    "            df_timestep.loc[i,'Kc_GHI_pred_improved'] = improved_GHI[-1][0,0]\n",
    "\n",
    "            # compute residual mean bias and residual bias covariance\n",
    "            if add_noise_in_predictions == True:\n",
    "                new_measurement = df_timestep.loc[i,'Kc_GHI_obs'] + np.random.normal(loc = 0, scale = V)\n",
    "            else:\n",
    "                new_measurement = df_timestep.loc[i,'Kc_GHI_obs']\n",
    "            residual_mean = new_measurement - dot(H,x_pred)\n",
    "            residual_covariance = dot(H, P).dot(H.T) + V\n",
    "\n",
    "            # compute Kalman gain based on the transition matrix and residual covariance\n",
    "            K = dot(P, H.T).dot(inv(residual_covariance)) # from documentation https://filterpy.readthedocs.io/en/latest/index.html#use\n",
    "            K = np.nan_to_num(K, nan = 0)\n",
    "\n",
    "            # update mean bias after incorporating measurements\n",
    "            x_pred = x_pred + dot(K,residual_mean)\n",
    "\n",
    "            # update bias covariance matrix after incorporating measurements\n",
    "            #P = dot(K,H).dot(P) # from https://www.youtube.com/watch?v=W0gai93yhsM\n",
    "            P = np.dot(np.eye(len(predictors_vector)) - dot(K,H),P)\n",
    "\n",
    "            measurement_GHI.append(new_measurement)\n",
    "            old_predicted_GHI.append(df_timestep.loc[i,'Kc_GHI_pred'])\n",
    "            ground_truths.append(df_timestep.loc[i,'Kc_GHI_obs'])\n",
    "\n",
    "        # assign final prediction\n",
    "        df_temp.loc[t,'Kc_GHI_pred_improved'] = improved_GHI[-1][0,0]\n",
    "    # calculate overall error metrics for this group of predictors\n",
    "    df_temp['GHI_pred_improved'] = df_temp['Kc_GHI_pred_improved'] * df_temp['GHI_in']\n",
    "\n",
    "    df_temp = df_temp.loc[~np.isnan(df_temp['GHI_pred_improved'])]\n",
    "    df_temp = df_temp.loc[~np.isnan(df_temp['ghi_obs'])]\n",
    "\n",
    "    rms = mean_squared_error(df_temp['ghi_obs'], df_temp['GHI_pred_improved'], squared=False)\n",
    "    mae = mean_absolute_error(df_temp['ghi_obs'], df_temp['GHI_pred_improved'])\n",
    "    mse = mean_squared_error(df_temp['ghi_obs'], df_temp['GHI_pred_improved'])\n",
    "    mbe = np.mean(df_temp['GHI_pred_improved'] - df_temp['ghi_obs'])\n",
    "\n",
    "    print('\\n\\n**************************')\n",
    "    print(f'Predictors: {predictors_vector}')\n",
    "    print(f'- RMS: {rms}')\n",
    "    print(f'- MAE: {mae}')\n",
    "    #print(f'- MSE: {mse}')\n",
    "    print(f'- MBE: {mbe}')\n",
    "\n",
    "    # assign post-processed timesteps to original dataframe\n",
    "    copy = df_temp[['Time','GHI_pred_improved']]\n",
    "\n",
    "\n",
    "    df_updated = df.merge(copy,how='outer',on=\"Time\")\n",
    "    df_updated['kf_obs'] = np.abs(df_updated['GHI_pred_improved'] - df_updated['ghi_obs'])\n",
    "    df_updated['wrf_obs'] = np.abs(df_updated['ghi_mod'] - df_updated['ghi_obs'])\n",
    "    \n",
    "    #Kalman Filter Alone\n",
    "    def kf_only(df):\n",
    "        if ((df['GHI_pred_improved'] >= 0)):\n",
    "            kf_only = df['GHI_pred_improved']\n",
    "        else:\n",
    "            kf_only = df['ghi_mod']\n",
    "        return(kf_only)\n",
    "    \n",
    "    df_updated[\"GHI_pred_kf_only\"] = df_updated.apply(kf_only, axis=1)\n",
    "    \n",
    "    #recording HITs and MISS for each LT or time of the day (Contingency Table)\n",
    "    def lim(df):\n",
    "        if ((df['GHI_pred_improved'] >= 0) & (df['kf_obs'] <= df['wrf_obs'])):\n",
    "            lim = 'HIT' #by KF\n",
    "        else:\n",
    "            lim = 'MISS'\n",
    "        return(lim)\n",
    "\n",
    "    df_updated[\"flag_hit\"] = df_updated.apply(lim, axis=1)\n",
    "\n",
    "    table = df_updated.groupby(['LT','flag_hit']).agg({'flag_hit': ['count']}).droplevel(axis=1, level=0).reset_index()#.to_csv('summary.csv')\n",
    "    table = pd.pivot_table(table, values='count', index=['LT'],columns=['flag_hit']).reset_index()#.to_csv('summary.csv')\n",
    "\n",
    "    #this will be used to know whether the WRF or KF output is better for each LT or time of the day\n",
    "    def hit(t):\n",
    "        if ((t['HIT'] >= 0) & (t['HIT'] >= t['MISS'])):\n",
    "            hit = 'KF'\n",
    "        else:\n",
    "            hit = 'WRF'\n",
    "        return(hit)\n",
    "    table[\"final\"] = table.apply(hit, axis=1)\n",
    "\n",
    "    df_updated = df_updated.merge(table,how='outer',on=\"LT\")\n",
    "    #depending on contingency table for each LT or time of the day \n",
    "    #use KF or WRF output\n",
    "    def final_pred(df):\n",
    "        if ((df['GHI_pred_improved'] >= 0) & (df['final'] == 'KF')):\n",
    "            lim = df['GHI_pred_improved']\n",
    "        else:\n",
    "            lim = df['ghi_mod']\n",
    "        return(lim)\n",
    "\n",
    "    df_updated[\"GHI_pred_improved_fin\"] = df_updated.apply(final_pred, axis=1)\n",
    "    df_updated = df_updated.sort_values(by='Time').reset_index()\n",
    "    #example for nb_historical_days=4\n",
    "    #we are only correcting for 29 while 48 points are retained\n",
    "    df_updated = df_updated[['Time',  'CMP22_Total_Solar', 'SPN1_Total_Solar',\n",
    "           'SPN1_Diff_Solar', 'CGR4_IR', 'dhi', 'ghi_a', 'sza', 'cossza', 'dni',\n",
    "           'MM', 'DD', 'HH', 'mm', 'GHI_in', 'DNI_in', 'DHI_in', 'cossza_b',\n",
    "           'SPN1_Total_Solar_N', 't2_lim', 'cossza_noon', 'FT_t', 'FT_TOA',\n",
    "           'FT_TOA_t', 't3_llim', 't3_ulim', 'Diffuse_Ratio', 'SPN1_Diff_Solar_N',\n",
    "           'sigma', 'ghi_cc_val', 'dhi_cc_val', 't1_lim', 'flag_clear', 'ghi_obs',\n",
    "           'ens', 'domain', 'station_name', 'variable', 'ghi_mod', 'YY',\n",
    "           'Error_rel', 'Kc_GHI_pred', 'Kc_GHI_obs', 'Kc_obs_bias', 'LT',\n",
    "           'GHI_pred_kf_only', 'GHI_pred_improved_fin']]\n",
    "    # calculate overall error metrics for this group of predictors\n",
    "    df_updated = df_updated.loc[~np.isnan(df_updated['GHI_pred_improved_fin'])]\n",
    "    df_updated = df_updated.loc[~np.isnan(df_updated['ghi_obs'])]\n",
    "\n",
    "    rms = mean_squared_error(df_updated['ghi_obs'], df_updated['GHI_pred_improved_fin'], squared=False)\n",
    "    mae = mean_absolute_error(df_updated['ghi_obs'], df_updated['GHI_pred_improved_fin'])\n",
    "    mse = mean_squared_error(df_updated['ghi_obs'], df_updated['GHI_pred_improved_fin'])\n",
    "    mbe = np.mean(df_updated['GHI_pred_improved_fin'] - df_updated['ghi_obs'])\n",
    "    \n",
    "    dir_path_recursive = f'{main_dir_path_recursive}/{ens}/{domain}/{station_name}/{nb_historical_days}_day'\n",
    "    os.makedirs(dir_path_recursive, exist_ok=True)\n",
    "    \n",
    "    ts_all(5, df_updated,dir_path_recursive)\n",
    "    scat_cloudy_all(5, df_updated,dir_path_recursive)\n",
    "    scat_clear_all(5, df_updated,dir_path_recursive)\n",
    "    \n",
    "    '''scat_all(5, df_updated)\n",
    "    ts_cut(5, df_updated)\n",
    "    scat_cut(5, df_updated)\n",
    "    scat_cloudy_cut(5, df_updated)\n",
    "    scat_clear_cut(5, df_updated)'''\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7877c930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
