{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5f7eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code makes diagnostic plots for raw and postprocessed WRF-Solar output\n",
    "Postprocessing using the Kalman Filter is from Rafael Alvarenga's code (rafael.alvarenga@etu.univ-guyane.fr)\n",
    "\"\"\"\n",
    "from file_func import *\n",
    "from plotting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171cbe3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9952ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "method='KF'\n",
    "def kalmanfi(df, df_temp, nb_LTs):\n",
    "    for nb_historical_days in [3,7,14,21,28,35,42,49,56,63,70]:\n",
    "    #for nb_historical_days in [nbhd]:\n",
    "        \n",
    "        timestep_enough_historical = (nb_historical_days*2)*nb_LTs  \n",
    "        \n",
    "        for t in tqdm(range(len(df_temp))):\n",
    "\n",
    "            hour = df_temp.loc[t,'Time'].hour\n",
    "            minutes = df_temp.loc[t,'Time'].minute\n",
    "\n",
    "            if t >= timestep_enough_historical:\n",
    "                # slice df_temp\n",
    "                df_timestep = df_temp.loc[t-(nb_historical_days*nb_LTs)-(nb_historical_days*nb_LTs*recursive_calculation_covariance_matrices):t,:].copy()\n",
    "            else:\n",
    "                df_timestep = df_temp.loc[t:t+(nb_historical_days*nb_LTs)+(nb_historical_days*nb_LTs*recursive_calculation_covariance_matrices),:].copy()\n",
    "                df_timestep = df_timestep[::-1].reset_index(drop=True)\n",
    "            df_timestep = df_timestep.loc[(df_timestep['Time'].dt.hour == hour) & (df_timestep['Time'].dt.minute == minutes)]\n",
    "            df_timestep = df_timestep.loc[~np.isnan(df_timestep['Kc_GHI_pred'])]\n",
    "            df_timestep = df_timestep.loc[~np.isnan(df_timestep['Kc_obs_bias'])]\n",
    "\n",
    "            if (len(df_timestep) == 0) & (len(df_timestep) <= nb_historical_days + (nb_historical_days*recursive_calculation_covariance_matrices) or (t not in df_timestep.index)):\n",
    "                df_temp.loc[t,'Kc_GHI_pred_improved'] = np.nan  \n",
    "                continue\n",
    "\n",
    "            df_timestep = df_timestep.iloc[-(nb_historical_days+1)-(nb_historical_days*recursive_calculation_covariance_matrices):,:]\n",
    "            df_timestep = df_timestep.reset_index(drop = True)\n",
    "\n",
    "            # define prediction-bias variance matrix\n",
    "            W = np.eye(len(predictors_vector))/1000\n",
    "\n",
    "            # define measurement-bias variance matrix\n",
    "            V = 0.01\n",
    "\n",
    "            # define initial error covariance matrix\n",
    "            Po = np.eye(len(predictors_vector))*5\n",
    "\n",
    "            # define initial predicted bias\n",
    "            xo = np.zeros(len(predictors_vector)).reshape(len(predictors_vector),1)\n",
    "\n",
    "            measurement_GHI = []\n",
    "            old_predicted_GHI = []\n",
    "            improved_GHI = []\n",
    "            ground_truths = []\n",
    "            predicted_coefs = []\n",
    "\n",
    "            for idx_i, i in enumerate(df_timestep.index):\n",
    "                if recursive_calculation_covariance_matrices == True:\n",
    "                    # --------------------------------------------\n",
    "                    #  Calculate matrices of covariance of errors\n",
    "                    # --------------------------------------------\n",
    "                    if idx_i > nb_historical_days:\n",
    "                        \n",
    "                        mean_w = sum(predicted_coefs[-(1+day)] - predicted_coefs[-(2+day)] for day in range(nb_historical_days))/nb_historical_days\n",
    "                        mean_v = sum(measurement_GHI[-(1+day)] - improved_GHI[-(1+day)] for day in range(nb_historical_days))/nb_historical_days\n",
    "\n",
    "                        # old method\n",
    "                        W = np.diag(list((1/(nb_historical_days-1))*sum(((predicted_coefs[-(1+day)] - predicted_coefs[-(2+day)]) - mean_w)**2 for day in range(nb_historical_days)).reshape(len(predictors_vector),)))\n",
    "                        V = (1/(nb_historical_days-1))*sum(((measurement_GHI[-(1+day)] - improved_GHI[-(1+day)]) - mean_v)**2 for day in range(nb_historical_days))\n",
    "\n",
    "                        # # improved method (from Lynch, 2014 - Simplified method to derive the Kalman Filter covariance matrices to predict wind speeds from a NWP model)\n",
    "                        # W = (1/(nb_historical_days-1))*sum(dot(((predicted_coefs[-(1+day)] - predicted_coefs[-(2+day)]) - mean_w),((predicted_coefs[-(1+day)] - predicted_coefs[-(2+day)]) - mean_w).T) for day in range(nb_historical_days))\n",
    "                        # V = (1/(nb_historical_days-1))*sum(dot(((measurement_GHI[-(1+day)] - improved_GHI[-(1+day)]) - mean_v),((measurement_GHI[-(1+day)] - improved_GHI[-(1+day)]) - mean_v).T) for day in range(nb_historical_days))\n",
    "\n",
    "                # ----------------------------\n",
    "                #           Predict\n",
    "                # ----------------------------\n",
    "\n",
    "                if idx_i == 0:\n",
    "                    # predicted mean bias\n",
    "                    x_pred = np.zeros_like(xo)\n",
    "                    if add_noise_in_predictions == True:\n",
    "                        x_pred = xo + np.random.multivariate_normal(mean=[0.5]*len(predictors_vector), cov=W, size=1).reshape(-1,1)\n",
    "                    else:\n",
    "                        x_pred = xo\n",
    "\n",
    "                    # predicted bias covariance matrix\n",
    "                    P = Po + W\n",
    "\n",
    "                else:\n",
    "                    # predicted mean bias\n",
    "                    if add_noise_in_predictions == True:\n",
    "                        x_pred = x_pred + np.random.multivariate_normal(mean=[0]*len(predictors_vector), cov=W, size=1).reshape(-1,1)\n",
    "                    else:\n",
    "                        x_pred = x_pred\n",
    "                    #x_pred[1:,0] = 0 # only bias is being tracked, our prediction model doesn't account for the other predictors\n",
    "\n",
    "                    # predicted bias covariance matrix\n",
    "                    P = P + W\n",
    "\n",
    "                # ----------------------------\n",
    "                #           Update\n",
    "                # ----------------------------\n",
    "\n",
    "                # compute transition matrix based on the current predictors for this timestep\n",
    "                H = [df_timestep.loc[i,predictor] for predictor in predictors_vector[1:]]\n",
    "                H = np.asarray([1] + H).reshape(1, len(predictors_vector))\n",
    "                if nonlinear_predictions == True:\n",
    "                    H = [predictor**idx_predictor for idx_predictor, predictor in enumerate(H)]\n",
    "\n",
    "                predicted_coefs.append(x_pred)\n",
    "                improved_GHI.append(dot(H,x_pred))\n",
    "                df_timestep.loc[i,'Kc_GHI_pred_improved'] = improved_GHI[-1][0,0]\n",
    "\n",
    "                # compute residual mean bias and residual bias covariance\n",
    "                if add_noise_in_predictions == True:\n",
    "                    new_measurement = df_timestep.loc[i,'Kc_GHI_obs'] + np.random.normal(loc = 0, scale = V)\n",
    "                else:\n",
    "                    new_measurement = df_timestep.loc[i,'Kc_GHI_obs']\n",
    "                residual_mean = new_measurement - dot(H,x_pred)\n",
    "                residual_covariance = dot(H, P).dot(H.T) + V\n",
    "\n",
    "                # compute Kalman gain based on the transition matrix and residual covariance\n",
    "                K = dot(P, H.T).dot(inv(residual_covariance)) # from documentation https://filterpy.readthedocs.io/en/latest/index.html#use\n",
    "                K = np.nan_to_num(K, nan = 0)\n",
    "\n",
    "                # update mean bias after incorporating measurements\n",
    "                x_pred = x_pred + dot(K,residual_mean)\n",
    "\n",
    "                # update bias covariance matrix after incorporating measurements\n",
    "                #P = dot(K,H).dot(P) # from https://www.youtube.com/watch?v=W0gai93yhsM\n",
    "                P = np.dot(np.eye(len(predictors_vector)) - dot(K,H),P)\n",
    "\n",
    "                measurement_GHI.append(new_measurement)\n",
    "                old_predicted_GHI.append(df_timestep.loc[i,'Kc_GHI_pred'])\n",
    "                ground_truths.append(df_timestep.loc[i,'Kc_GHI_obs'])\n",
    "\n",
    "            # assign final prediction\n",
    "            df_temp.loc[t,'Kc_GHI_pred_improved'] = improved_GHI[-1][0,0]\n",
    "        # calculate overall error metrics for this group of predictors\n",
    "        df_temp['GHI_pred_improved'] = df_temp['Kc_GHI_pred_improved'] * df_temp['GHI_in']\n",
    "\n",
    "        df_temp = df_temp.loc[~np.isnan(df_temp['GHI_pred_improved'])]\n",
    "        df_temp = df_temp.loc[~np.isnan(df_temp['ghi_obs'])]\n",
    "\n",
    "        rms = mean_squared_error(df_temp['ghi_obs'], df_temp['GHI_pred_improved'], squared=False)\n",
    "        mae = mean_absolute_error(df_temp['ghi_obs'], df_temp['GHI_pred_improved'])\n",
    "        mse = mean_squared_error(df_temp['ghi_obs'], df_temp['GHI_pred_improved'])\n",
    "        mbe = np.mean(df_temp['GHI_pred_improved'] - df_temp['ghi_obs'])\n",
    "\n",
    "        print('\\n\\n**************************')\n",
    "        print(f'Predictors: {predictors_vector}')\n",
    "        print(f'- RMS: {rms}')\n",
    "        print(f'- MAE: {mae}')\n",
    "        #print(f'- MSE: {mse}')\n",
    "        print(f'- MBE: {mbe}')\n",
    "\n",
    "        # assign post-processed timesteps to original dataframe\n",
    "        copy = df_temp[['Time','GHI_pred_improved']]\n",
    "\n",
    "\n",
    "        df_updated = df.merge(copy,how='outer',on=\"Time\")\n",
    "        df_updated['kf_obs'] = np.abs(df_updated['GHI_pred_improved'] - df_updated['ghi_obs'])\n",
    "        df_updated['wrf_obs'] = np.abs(df_updated['ghi_mod'] - df_updated['ghi_obs'])\n",
    "\n",
    "        #Kalman Filter Alone\n",
    "        def kf_only(df):\n",
    "            if ((df['GHI_pred_improved'] >= 0)):\n",
    "                kf_only = df['GHI_pred_improved']\n",
    "            else:\n",
    "                kf_only = df['ghi_mod']\n",
    "            return(kf_only)\n",
    "\n",
    "        df_updated[\"GHI_pred_kf_only\"] = df_updated.apply(kf_only, axis=1)\n",
    "\n",
    "        #recording HITs and MISS for each LT or time of the day (Contingency Table)\n",
    "        def lim(df):\n",
    "            if ((df['GHI_pred_improved'] >= 0) & (df['kf_obs'] <= df['wrf_obs'])):\n",
    "                lim = 'HIT' #by KF\n",
    "            else:\n",
    "                lim = 'MISS'\n",
    "            return(lim)\n",
    "\n",
    "        df_updated[\"flag_hit\"] = df_updated.apply(lim, axis=1)\n",
    "\n",
    "        table = df_updated.groupby(['LT','flag_hit']).agg({'flag_hit': ['count']}).droplevel(axis=1, level=0).reset_index()#.to_csv('summary.csv')\n",
    "        table = pd.pivot_table(table, values='count', index=['LT'],columns=['flag_hit']).reset_index()#.to_csv('summary.csv')\n",
    "\n",
    "        #this will be used to know whether the WRF or KF output is better for each LT or time of the day\n",
    "        def hit(t):\n",
    "            if ((t['HIT'] >= 0) & (t['HIT'] >= t['MISS'])):\n",
    "                hit = 'KF'\n",
    "            else:\n",
    "                hit = 'WRF'\n",
    "            return(hit)\n",
    "        table[\"final\"] = table.apply(hit, axis=1)\n",
    "\n",
    "        df_updated = df_updated.merge(table,how='outer',on=\"LT\")\n",
    "        #depending on contingency table for each LT or time of the day \n",
    "        #use KF or WRF output\n",
    "        def final_pred(df):\n",
    "            if ((df['GHI_pred_improved'] >= 0) & (df['final'] == 'KF')):\n",
    "                lim = df['GHI_pred_improved']\n",
    "            else:\n",
    "                lim = df['ghi_mod']\n",
    "            return(lim)\n",
    "\n",
    "        df_updated[\"GHI_pred_improved_fin\"] = df_updated.apply(final_pred, axis=1)\n",
    "        df_updated = df_updated.sort_values(by='Time').reset_index()\n",
    "        #example for nb_historical_days=4\n",
    "        #we are only correcting for 29 while 48 points are retained\n",
    "        df_updated = df_updated[['Time',  'CMP22_Total_Solar', 'SPN1_Total_Solar',\n",
    "               'SPN1_Diff_Solar', 'CGR4_IR', 'dhi', 'ghi_a', 'sza', 'cossza', 'dni',\n",
    "               'MM', 'DD', 'HH', 'mm', 'GHI_in', 'DNI_in', 'DHI_in', 'cossza_b',\n",
    "               'SPN1_Total_Solar_N', 't2_lim', 'cossza_noon', 'FT_t', 'FT_TOA',\n",
    "               'FT_TOA_t', 't3_llim', 't3_ulim', 'Diffuse_Ratio', 'SPN1_Diff_Solar_N',\n",
    "               'sigma', 'ghi_cc_val', 'dhi_cc_val', 't1_lim', 'flag_clear', 'ghi_obs',\n",
    "               'ens', 'domain', 'station_name', 'ghi_mod', 'YY',\n",
    "               'Error_rel', 'Kc_GHI_pred', 'Kc_GHI_obs', 'Kc_obs_bias', 'LT',\n",
    "               'GHI_pred_kf_only', 'GHI_pred_improved_fin']]\n",
    "        # calculate overall error metrics for this group of predictors\n",
    "        df_updated = df_updated[df_updated['ghi_mod']  > 0]\n",
    "        df_updated = df_updated.loc[~np.isnan(df_updated['GHI_pred_improved_fin'])]\n",
    "        df_updated = df_updated.loc[~np.isnan(df_updated['ghi_obs'])]\n",
    "\n",
    "        rms = mean_squared_error(df_updated['ghi_obs'], df_updated['GHI_pred_improved_fin'], squared=False)\n",
    "        mae = mean_absolute_error(df_updated['ghi_obs'], df_updated['GHI_pred_improved_fin'])\n",
    "        mse = mean_squared_error(df_updated['ghi_obs'], df_updated['GHI_pred_improved_fin'])\n",
    "        mbe = np.mean(df_updated['GHI_pred_improved_fin'] - df_updated['ghi_obs'])\n",
    "\n",
    "        dir_path_recursive = f'{main_dir_path_recursive}/{ens}/{domain}/{station_name}/{nb_historical_days}_day_{method}'\n",
    "        os.makedirs(dir_path_recursive, exist_ok=True)\n",
    "\n",
    "        nb_historical_days = dir_path_recursive.split('/')[4]\n",
    "        ensemble_member = dir_path_recursive.split('/')[1]\n",
    "        df_updated.iloc[nb_LTs*nbhd:,:].to_csv(f\"{dir_path_recursive}/{ensemble_member}_{domain}_{nb_historical_days}_df_cut.csv\")\n",
    "        \n",
    "        df_updated.to_csv(f\"{dir_path_recursive}/{ensemble_member}_{domain}_{nb_historical_days}_df.csv\")\n",
    "        \n",
    "        ts_all(res, df_updated,dir_path_recursive)\n",
    "        ts_cut(res, df_updated,dir_path_recursive, nb_LTs)\n",
    "        scat_cloudy_all(res, df_updated,dir_path_recursive)\n",
    "        scat_clear_all(res, df_updated,dir_path_recursive)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00510bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 4691/4691 [01:10<00:00, 66.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************\n",
      "Predictors: ['Kc_GHI_pred', 'cossza']\n",
      "- RMS: 240.3011480936169\n",
      "- MAE: 180.36502514862843\n",
      "- MBE: -12.130290553697883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 4691/4691 [01:59<00:00, 39.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************\n",
      "Predictors: ['Kc_GHI_pred', 'cossza']\n",
      "- RMS: 235.55991581178628\n",
      "- MAE: 175.81659787806117\n",
      "- MBE: -9.771080007021508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 4691/4691 [03:30<00:00, 22.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************\n",
      "Predictors: ['Kc_GHI_pred', 'cossza']\n",
      "- RMS: 233.78186494864858\n",
      "- MAE: 175.56148860184763\n",
      "- MBE: -4.760283678164759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████▎                      | 1966/4691 [02:13<03:07, 14.57it/s]"
     ]
    }
   ],
   "source": [
    "#for ens in ['ens0','ens1','ens2', 'ens3', 'ensmean']:\n",
    "for ens in ['ens2']:\n",
    "    #for domain in ['d01', 'd02']:\n",
    "    for domain in ['d01']:\n",
    "    \n",
    "        \n",
    "        if domain == 'd01':\n",
    "            res = 5\n",
    "        elif domain == 'd02':\n",
    "            res = 1\n",
    "        \n",
    "        a = prep_input()[0]\n",
    "        mod_ = prep_input()[1]\n",
    "\n",
    "        os.makedirs(main_dir_path_recursive, exist_ok=True)\n",
    "\n",
    "        df = prep_opt(mod_, a, ens, domain)[0]\n",
    "        df_temp = prep_opt(mod_, a, ens, domain)[1]\n",
    "\n",
    "        nb_LTs = len(np.unique(df_temp.LT))\n",
    "        \n",
    "        method='KF'\n",
    "        \n",
    "        kalmanfi(df, df_temp, nb_LTs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788c5f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''method= 'ANKF'\n",
    "#for nb_historical_days in [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]:\n",
    "for nb_historical_days in [11]:\n",
    "    #nb_historical_days = 11\n",
    "    timestep_enough_historical = (nb_historical_days*2)*nb_LTs  \n",
    "    for t in tqdm(range(len(df_temp))):\n",
    "\n",
    "        # slice df to find analogs\n",
    "        df_temp['date'] = df_temp['Time'].dt.date \n",
    "        \n",
    "        # create hour column\n",
    "        df_temp['TIME'] = df_temp['Time'].dt.time \n",
    "\n",
    "        # define variables to analyse when searching for analogs\n",
    "        variables_to_search = ['Kc_GHI_pred','meanCC','T2']\n",
    "\n",
    "        # define weights of each variable when searching for analogs\n",
    "        weights_variables = {'Kc_GHI_pred': 0.7,\n",
    "                             'T2': 0.3}\n",
    "        \n",
    "        df_timestep = df_temp.loc[:t,:].copy()\n",
    "        df_timestep = df_timestep.loc[(df_timestep['Time'].dt.hour >= hour-1) & (df_timestep['Time'].dt.hour <= hour+1),:]\n",
    "        df_timestep = df_timestep.loc[~np.isnan(df_timestep['Kc_GHI_pred'])]\n",
    "        df_timestep = df_timestep.loc[~np.isnan(df_timestep['Kc_obs_bias'])]\n",
    "   \n",
    "        if (len(df_timestep) == 0) & (len(np.unique(df_timestep['date'])) <= nb_historical_days + (nb_historical_days*recursive_calculation_covariance_matrices)) or (t not in df_timestep.index):\n",
    "            df_temp.loc[t,'Kc_GHI_pred_improved'] = np.nan  \n",
    "            continue\n",
    "        \n",
    "        # ----------------------------\n",
    "        #     Search for analogs\n",
    "        # ----------------------------\n",
    "\n",
    "        analogs = []\n",
    "        for date in np.unique(df_timestep.Time.dt.date[:-1]):\n",
    "            dist = 0\n",
    "            for variable in variables_to_search:              \n",
    "                analog = df_timestep.loc[df_timestep.Time.dt.date == date,['Time','TIME',variable]]\n",
    "                try:\n",
    "                    idx_right = analog.loc[(analog['Time'].dt.hour == hour) & (analog['Time'].dt.minute == minutes)].index[0]\n",
    "                except:\n",
    "                    dist = np.nan\n",
    "                idx_ini = list(analog.index)[0]\n",
    "                idx_fin = list(analog.index)[-1]\n",
    "                \n",
    "                current_prediction = df_temp.loc[(t-(idx_right-idx_ini)):(t+(idx_fin-idx_right)),['Time',variable]]\n",
    "                current_prediction['TIME'] = current_prediction['Time'].dt.time\n",
    "                analog = analog[['TIME',variable]].merge(current_prediction[['TIME',variable]], how='left', left_on='TIME',right_on='TIME')\n",
    "                analog = analog.dropna()\n",
    "                \n",
    "                dist = dist + (weights_variables[variable]/df_timestep[variable].std()*np.sqrt(sum((analog.iloc[k,1] - analog.iloc[k,2])**2 for k in range(len(analog)))))\n",
    "                \n",
    "                del current_prediction\n",
    "            analogs.append([date,dist])\n",
    "        analogs = np.asarray(analogs)\n",
    "        \n",
    "        # remove NaN values\n",
    "        analogs = analogs[np.argwhere(~np.isnan(analogs[:,1].astype(float)))[:,0]]\n",
    "        \n",
    "        # sort analogs according to distance\n",
    "        analogs = analogs[np.argsort(analogs[:, 1])]\n",
    "        \n",
    "        # get dates of only the nb of analogs chosen previously\n",
    "        analogs = list(analogs[:(nb_historical_days+(nb_historical_days*recursive_calculation_covariance_matrices)),0])\n",
    "        \n",
    "        # replace dataframe for the current prediction timestep + analogs\n",
    "        columns = df_timestep.columns\n",
    "        df_timestep = df_timestep.loc[(df_timestep['Time'] == list(df_timestep.Time)[-1]) & (df_timestep['Time'].dt.hour == hour) & (df_timestep['DATE'].dt.minute == minutes)].values.tolist()\n",
    "        for date in analogs:\n",
    "            df_timestep.append(df_temp.loc[(df_temp['Time'].dt.date == date) & (df_temp['Time'].dt.hour == hour) & (df_temp['Time'].dt.minute == minutes)].values.tolist()[0])\n",
    "        df_timestep = pd.DataFrame(df_timestep, columns = columns)\n",
    "        df_timestep = df_timestep[::-1].reset_index(drop = True)\n",
    "\n",
    "        # define prediction-bias variance matrix\n",
    "        W = np.eye(len(predictors_vector))/1000\n",
    "\n",
    "        # define measurement-bias variance matrix\n",
    "        V = 0.01\n",
    "\n",
    "        # define initial error covariance matrix\n",
    "        Po = np.eye(len(predictors_vector))*5\n",
    "\n",
    "        # define initial predicted bias\n",
    "        xo = np.zeros(len(predictors_vector)).reshape(len(predictors_vector),1)\n",
    "\n",
    "        measurement_GHI = []\n",
    "        old_predicted_GHI = []\n",
    "        improved_GHI = []\n",
    "        ground_truths = []\n",
    "        predicted_coefs = []\n",
    "\n",
    "        for idx_i, i in enumerate(df_timestep.index):\n",
    "            if recursive_calculation_covariance_matrices == True:\n",
    "                # --------------------------------------------\n",
    "                #  Calculate matrices of covariance of errors\n",
    "                # --------------------------------------------\n",
    "                if idx_i > nb_historical_days:\n",
    "                    mean_w = sum(predicted_coefs[-(1+day)] - predicted_coefs[-(2+day)] for day in range(nb_historical_days))/nb_historical_days\n",
    "                    mean_v = sum(measurement_GHI[-(1+day)] - improved_GHI[-(1+day)] for day in range(nb_historical_days))/nb_historical_days\n",
    "\n",
    "                    # old method\n",
    "                    W = np.diag(list((1/(nb_historical_days-1))*sum(((predicted_coefs[-(1+day)] - predicted_coefs[-(2+day)]) - mean_w)**2 for day in range(nb_historical_days)).reshape(len(predictors_vector),)))\n",
    "                    V = (1/(nb_historical_days-1))*sum(((measurement_GHI[-(1+day)] - improved_GHI[-(1+day)]) - mean_v)**2 for day in range(nb_historical_days))\n",
    "\n",
    "                    # # improved method (from Lynch, 2014 - Simplified method to derive the Kalman Filter covariance matrices to predict wind speeds from a NWP model)\n",
    "                    # W = (1/(nb_historical_days-1))*sum(dot(((predicted_coefs[-(1+day)] - predicted_coefs[-(2+day)]) - mean_w),((predicted_coefs[-(1+day)] - predicted_coefs[-(2+day)]) - mean_w).T) for day in range(nb_historical_days))\n",
    "                    # V = (1/(nb_historical_days-1))*sum(dot(((measurement_GHI[-(1+day)] - improved_GHI[-(1+day)]) - mean_v),((measurement_GHI[-(1+day)] - improved_GHI[-(1+day)]) - mean_v).T) for day in range(nb_historical_days))\n",
    "\n",
    "            # ----------------------------\n",
    "            #           Predict\n",
    "            # ----------------------------\n",
    "\n",
    "            if idx_i == 0:\n",
    "                # predicted mean bias\n",
    "                x_pred = np.zeros_like(xo)\n",
    "                if add_noise_in_predictions == True:\n",
    "                    x_pred = xo + np.random.multivariate_normal(mean=[0.5]*len(predictors_vector), cov=W, size=1).reshape(-1,1)\n",
    "                else:\n",
    "                    x_pred = xo\n",
    "\n",
    "                # predicted bias covariance matrix\n",
    "                P = Po + W\n",
    "\n",
    "            else:\n",
    "                # predicted mean bias\n",
    "                if add_noise_in_predictions == True:\n",
    "                    x_pred = x_pred + np.random.multivariate_normal(mean=[0]*len(predictors_vector), cov=W, size=1).reshape(-1,1)\n",
    "                else:\n",
    "                    x_pred = x_pred\n",
    "                #x_pred[1:,0] = 0 # only bias is being tracked, our prediction model doesn't account for the other predictors\n",
    "\n",
    "                # predicted bias covariance matrix\n",
    "                P = P + W\n",
    "\n",
    "            # ----------------------------\n",
    "            #           Update\n",
    "            # ----------------------------\n",
    "\n",
    "            # compute transition matrix based on the current predictors for this timestep\n",
    "            H = [df_timestep.loc[i,predictor] for predictor in predictors_vector[1:]]\n",
    "            H = np.asarray([1] + H).reshape(1, len(predictors_vector))\n",
    "            if nonlinear_predictions == True:\n",
    "                H = [predictor**idx_predictor for idx_predictor, predictor in enumerate(H)]\n",
    "\n",
    "            predicted_coefs.append(x_pred)\n",
    "            improved_GHI.append(dot(H,x_pred))\n",
    "            df_timestep.loc[i,'Kc_GHI_pred_improved'] = improved_GHI[-1][0,0]\n",
    "\n",
    "            # compute residual mean bias and residual bias covariance\n",
    "            if add_noise_in_predictions == True:\n",
    "                new_measurement = df_timestep.loc[i,'Kc_GHI_obs'] + np.random.normal(loc = 0, scale = V)\n",
    "            else:\n",
    "                new_measurement = df_timestep.loc[i,'Kc_GHI_obs']\n",
    "            residual_mean = new_measurement - dot(H,x_pred)\n",
    "            residual_covariance = dot(H, P).dot(H.T) + V\n",
    "\n",
    "            # compute Kalman gain based on the transition matrix and residual covariance\n",
    "            K = dot(P, H.T).dot(inv(residual_covariance)) # from documentation https://filterpy.readthedocs.io/en/latest/index.html#use\n",
    "            K = np.nan_to_num(K, nan = 0)\n",
    "\n",
    "            # update mean bias after incorporating measurements\n",
    "            x_pred = x_pred + dot(K,residual_mean)\n",
    "\n",
    "            # update bias covariance matrix after incorporating measurements\n",
    "            #P = dot(K,H).dot(P) # from https://www.youtube.com/watch?v=W0gai93yhsM\n",
    "            P = np.dot(np.eye(len(predictors_vector)) - dot(K,H),P)\n",
    "\n",
    "            measurement_GHI.append(new_measurement)\n",
    "            old_predicted_GHI.append(df_timestep.loc[i,'Kc_GHI_pred'])\n",
    "            ground_truths.append(df_timestep.loc[i,'Kc_GHI_obs'])\n",
    "\n",
    "        # assign final prediction\n",
    "        df_temp.loc[t,'Kc_GHI_pred_improved'] = improved_GHI[-1][0,0]\n",
    "    # calculate overall error metrics for this group of predictors\n",
    "    df_temp['GHI_pred_improved'] = df_temp['Kc_GHI_pred_improved'] * df_temp['GHI_in']\n",
    "\n",
    "    df_temp = df_temp.loc[~np.isnan(df_temp['GHI_pred_improved'])]\n",
    "    df_temp = df_temp.loc[~np.isnan(df_temp['ghi_obs'])]\n",
    "\n",
    "    rms = mean_squared_error(df_temp['ghi_obs'], df_temp['GHI_pred_improved'], squared=False)\n",
    "    mae = mean_absolute_error(df_temp['ghi_obs'], df_temp['GHI_pred_improved'])\n",
    "    mse = mean_squared_error(df_temp['ghi_obs'], df_temp['GHI_pred_improved'])\n",
    "    mbe = np.mean(df_temp['GHI_pred_improved'] - df_temp['ghi_obs'])\n",
    "\n",
    "    print('\\n\\n**************************')\n",
    "    print(f'Predictors: {predictors_vector}')\n",
    "    print(f'- RMS: {rms}')\n",
    "    print(f'- MAE: {mae}')\n",
    "    #print(f'- MSE: {mse}')\n",
    "    print(f'- MBE: {mbe}')\n",
    "\n",
    "    # assign post-processed timesteps to original dataframe\n",
    "    copy = df_temp[['Time','GHI_pred_improved']]\n",
    "\n",
    "\n",
    "    df_updated = df.merge(copy,how='outer',on=\"Time\")\n",
    "    df_updated['kf_obs'] = np.abs(df_updated['GHI_pred_improved'] - df_updated['ghi_obs'])\n",
    "    df_updated['wrf_obs'] = np.abs(df_updated['ghi_mod'] - df_updated['ghi_obs'])\n",
    "    \n",
    "    #Kalman Filter Alone\n",
    "    def kf_only(df):\n",
    "        if ((df['GHI_pred_improved'] >= 0)):\n",
    "            kf_only = df['GHI_pred_improved']\n",
    "        else:\n",
    "            kf_only = df['ghi_mod']\n",
    "        return(kf_only)\n",
    "    \n",
    "    df_updated[\"GHI_pred_kf_only\"] = df_updated.apply(kf_only, axis=1)\n",
    "    \n",
    "    #recording HITs and MISS for each LT or time of the day (Contingency Table)\n",
    "    def lim(df):\n",
    "        if ((df['GHI_pred_improved'] >= 0) & (df['kf_obs'] <= df['wrf_obs'])):\n",
    "            lim = 'HIT' #by KF\n",
    "        else:\n",
    "            lim = 'MISS'\n",
    "        return(lim)\n",
    "\n",
    "    df_updated[\"flag_hit\"] = df_updated.apply(lim, axis=1)\n",
    "\n",
    "    table = df_updated.groupby(['LT','flag_hit']).agg({'flag_hit': ['count']}).droplevel(axis=1, level=0).reset_index()#.to_csv('summary.csv')\n",
    "    table = pd.pivot_table(table, values='count', index=['LT'],columns=['flag_hit']).reset_index()#.to_csv('summary.csv')\n",
    "\n",
    "    #this will be used to know whether the WRF or KF output is better for each LT or time of the day\n",
    "    def hit(t):\n",
    "        if ((t['HIT'] >= 0) & (t['HIT'] >= t['MISS'])):\n",
    "            hit = 'KF'\n",
    "        else:\n",
    "            hit = 'WRF'\n",
    "        return(hit)\n",
    "    table[\"final\"] = table.apply(hit, axis=1)\n",
    "\n",
    "    df_updated = df_updated.merge(table,how='outer',on=\"LT\")\n",
    "    #depending on contingency table for each LT or time of the day \n",
    "    #use KF or WRF output\n",
    "    def final_pred(df):\n",
    "        if ((df['GHI_pred_improved'] >= 0) & (df['final'] == 'KF')):\n",
    "            lim = df['GHI_pred_improved']\n",
    "        else:\n",
    "            lim = df['ghi_mod']\n",
    "        return(lim)\n",
    "\n",
    "    df_updated[\"GHI_pred_improved_fin\"] = df_updated.apply(final_pred, axis=1)\n",
    "    df_updated = df_updated.sort_values(by='Time').reset_index()\n",
    "    #example for nb_historical_days=4\n",
    "    #we are only correcting for 29 while 48 points are retained\n",
    "    df_updated = df_updated[['Time',  'CMP22_Total_Solar', 'SPN1_Total_Solar',\n",
    "           'SPN1_Diff_Solar', 'CGR4_IR', 'dhi', 'ghi_a', 'sza', 'cossza', 'dni',\n",
    "           'MM', 'DD', 'HH', 'mm', 'GHI_in', 'DNI_in', 'DHI_in', 'cossza_b',\n",
    "           'SPN1_Total_Solar_N', 't2_lim', 'cossza_noon', 'FT_t', 'FT_TOA',\n",
    "           'FT_TOA_t', 't3_llim', 't3_ulim', 'Diffuse_Ratio', 'SPN1_Diff_Solar_N',\n",
    "           'sigma', 'ghi_cc_val', 'dhi_cc_val', 't1_lim', 'flag_clear', 'ghi_obs',\n",
    "           'ens', 'domain', 'station_name', 'ghi_mod', 'YY',\n",
    "           'Error_rel', 'Kc_GHI_pred', 'Kc_GHI_obs', 'Kc_obs_bias', 'LT',\n",
    "           'GHI_pred_kf_only', 'GHI_pred_improved_fin']]\n",
    "    # calculate overall error metrics for this group of predictors\n",
    "    df_updated = df_updated.loc[~np.isnan(df_updated['GHI_pred_improved_fin'])]\n",
    "    df_updated = df_updated.loc[~np.isnan(df_updated['ghi_obs'])]\n",
    "\n",
    "    rms = mean_squared_error(df_updated['ghi_obs'], df_updated['GHI_pred_improved_fin'], squared=False)\n",
    "    mae = mean_absolute_error(df_updated['ghi_obs'], df_updated['GHI_pred_improved_fin'])\n",
    "    mse = mean_squared_error(df_updated['ghi_obs'], df_updated['GHI_pred_improved_fin'])\n",
    "    mbe = np.mean(df_updated['GHI_pred_improved_fin'] - df_updated['ghi_obs'])\n",
    "    \n",
    "    dir_path_recursive = f'{main_dir_path_recursive}/{ens}/{domain}/{station_name}/{nb_historical_days}_day_{method}'\n",
    "    os.makedirs(dir_path_recursive, exist_ok=True)\n",
    "    \n",
    "    ts_all(res, df_updated,dir_path_recursive)\n",
    "    scat_cloudy_all(res, df_updated,dir_path_recursive)\n",
    "    scat_clear_all(res, df_updated,dir_path_recursive)\n",
    "    \n",
    "    '''\n",
    "    '''scat_all(res, df_updated)\n",
    "    ts_cut(res, df_updated)\n",
    "    scat_cut(res, df_updated)\n",
    "    scat_cloudy_cut(res, df_updated)\n",
    "    scat_clear_cut(res, df_updated)'''\n",
    "\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a49ed8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
