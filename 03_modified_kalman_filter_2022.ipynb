{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f7eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code makes diagnostic plots for raw and postprocessed WRF-Solar output\n",
    "Postprocessing using the Kalman Filter is from Rafael Alvarenga's code (rafael.alvarenga@etu.univ-guyane.fr)\n",
    "\"\"\"\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "import matplotlib.dates as md\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import pytz\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import kendalltau\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4bbbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tz = pytz.timezone(\"Asia/Manila\")\n",
    "resolution = '10Min'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655c7957",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('with_flags.csv')\n",
    "a['Time'] = pd.to_datetime(a['Time'])\n",
    "\n",
    "a['ghi_obs'] = a['SPN1_Total_Solar']\n",
    "a.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d2ffbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e6f12b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b688d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/apple/Desktop/Others/Python_Codes/wrf_solar/csv_2022_runs/' # use your path\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "mod_ = []\n",
    "\n",
    "for f in all_files:\n",
    "    mod = pd.read_csv(f)\n",
    "    mod['Time'] = pd.to_datetime(mod['time'])#.dt.tz_localize(tz)\n",
    "    mod = mod.set_index('Time')\n",
    "    t0 = mod.index[0] + datetime.timedelta(hours=21)\n",
    "    tf = t0 + datetime.timedelta(hours=14)\n",
    "    mod['plot'] = 'N'\n",
    "    mod.loc[((mod.index >= t0) & (mod.index<= tf)), 'plot'] = 'Y'\n",
    "    mod=mod[mod['plot']=='Y']\n",
    "    mod = mod.reset_index()\n",
    "    mod_.append(mod)\n",
    "    \n",
    "mod_ = pd.concat(mod_)\n",
    "\n",
    "\n",
    "mod_ = mod_[['Time', 'ens', 'ghi', 'swddni', 'coszen', 'swddif', 'lon', 'lat', 'hour', 'station_name',\n",
    "       'domain']]\n",
    "\n",
    "\n",
    "mod_ = pd.melt(mod_, id_vars=['Time', 'ens', 'domain', 'station_name'], value_vars=['ghi'] ,value_name='ghi_mod')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6264ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MO\n",
    "\n",
    "#ensmean\n",
    "mod_d01 = mod_[(mod_['ens']== 'ensmean') & (mod_['domain']== 'd01') & (mod_['station_name']== 'MO')]\n",
    "mod_d02 = mod_[(mod_['ens']== 'ensmean') & (mod_['domain']== 'd02') & (mod_['station_name']== 'MO')]\n",
    "mod_d01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2560f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_d01.to_csv('sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779c61b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_d01  = mod_d01.set_index('Time')\n",
    "#mod_d01  = mod_d01.resample(resolution).interpolate(method='linear')\n",
    "mod_d01  = mod_d01.reset_index(drop = False)\n",
    "mod_d01['station_name']  = 'MO'\n",
    "mod_d01['domain']  = 'd01'\n",
    "mod_d01['ens']  = 'ensmean'\n",
    "\n",
    "mod_d02  = mod_d02.set_index('Time')\n",
    "#mod_d02  = mod_d02.resample(resolution).interpolate(method='linear')\n",
    "mod_d02  = mod_d02.reset_index(drop = False)\n",
    "mod_d02['station_name']  = 'MO'\n",
    "mod_d02['domain']  = 'd02'\n",
    "mod_d02['ens']  = 'ensmean'\n",
    "\n",
    "d01_mo_mean = a.merge(mod_d01, how='inner', on='Time')\n",
    "d01_mo_mean['Time'] = pd.to_datetime(d01_mo_mean['Time']).dt.tz_convert(tz)\n",
    "\n",
    "\n",
    "d01_mo_mean = d01_mo_mean.set_index('Time')\n",
    "d01_mo_mean['YY'] = pd.DatetimeIndex(d01_mo_mean.index).year\n",
    "d01_mo_mean['MM'] = pd.DatetimeIndex(d01_mo_mean.index).month\n",
    "d01_mo_mean['DD'] = pd.DatetimeIndex(d01_mo_mean.index).day\n",
    "d01_mo_mean['HH'] = pd.DatetimeIndex(d01_mo_mean.index).hour\n",
    "d01_mo_mean['mm'] = pd.DatetimeIndex(d01_mo_mean.index).minute\n",
    "d01_mo_mean = d01_mo_mean.reset_index()\n",
    "\n",
    "\n",
    "d02_mo_mean = a.merge(mod_d02, how='inner', on='Time')\n",
    "d02_mo_mean['Time'] = pd.to_datetime(d02_mo_mean['Time']).dt.tz_convert(tz)\n",
    "\n",
    "\n",
    "d02_mo_mean = d02_mo_mean.set_index('Time')\n",
    "d02_mo_mean['YY'] = pd.DatetimeIndex(d02_mo_mean.index).year\n",
    "d02_mo_mean['MM'] = pd.DatetimeIndex(d02_mo_mean.index).month\n",
    "d02_mo_mean['DD'] = pd.DatetimeIndex(d02_mo_mean.index).day\n",
    "d02_mo_mean['HH'] = pd.DatetimeIndex(d02_mo_mean.index).hour\n",
    "d02_mo_mean['mm'] = pd.DatetimeIndex(d02_mo_mean.index).minute\n",
    "d02_mo_mean = d02_mo_mean.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afe7bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d01_mo_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c97a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = d01_mo_mean\n",
    "if 'Error_rel' not in df.columns:\n",
    "    # Function to calculate relative errors\n",
    "    def calculate_relative_errors(pred, obs):\n",
    "        if obs == 0:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return (pred - obs)/obs\n",
    "    # recalculate relative error after removing some observations\n",
    "    df['Error_rel'] = df.apply(lambda row : calculate_relative_errors(row['ghi_mod'], row['ghi_obs']), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a6942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#line 221\n",
    "df['Kc_GHI_pred'] = df['ghi_mod']/df['GHI_in']\n",
    "df['Kc_GHI_pred'] = df['Kc_GHI_pred'].replace(np.inf,np.nan)\n",
    "\n",
    "##############################\n",
    "#CHECK THIS###################\n",
    "##############################\n",
    "df['Kc_GHI_obs'] = df['ghi_obs']/df['GHI_in']\n",
    "\n",
    "#line 223\n",
    "# create clear-sky index column for observed errors \n",
    "df['Kc_obs_bias'] = df['Kc_GHI_pred'] - df['Kc_GHI_obs']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc4e951",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['LT'] = (df['HH']*60)+df['mm']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5e7e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "#    Remove early morning and late afternoon\n",
    "# ----------------------------\n",
    "df_temp = df.loc[(df['Time'].dt.hour >= 8) & (df['Time'].dt.hour <= 17)].copy()\n",
    "idx_remove = df_temp.loc[(df_temp['Time'].dt.hour == 17) & (df_temp['Time'].dt.minute != 0)].index\n",
    "df_temp.drop(idx_remove, axis=0, inplace=True)\n",
    "df_temp = df_temp.reset_index(drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d291a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for predictors_vector in [['Kc_GHI_pred','Q2_rel']]:# [results_best_MBE.loc[results_best_MBE.index[-1], 'Predictors'].split('-')[1:], results_best_MAE.loc[results_best_MAE.index[-1], 'Predictors'].split('-')[1:]]:\n",
    "#df_temp = df.copy()\n",
    "df_temp['Kc_GHI_pred_improved'] = np.nan \n",
    "\n",
    "##############################\n",
    "#CHECK THIS###################\n",
    "##############################\n",
    "df_temp['predicted_coefs'] = np.nan \n",
    "df_temp =  df_temp[['Time', 'LT','CMP22_Total_Solar', 'SPN1_Total_Solar',\n",
    "       'SPN1_Diff_Solar', 'CGR4_IR', 'YY', 'MM', 'HH', 'mm', 'dhi',\n",
    "       'ghi_obs', 'sza', 'cossza', 'dni',  'GHI_in', 'DNI_in', 'DHI_in', 'cossza_b',\n",
    "       'SPN1_Total_Solar_N', 't2_lim', 'cossza_noon', 'FT_t', 'FT_TOA',\n",
    "       'FT_TOA_t', 't3_llim', 't3_ulim', 'Diffuse_Ratio', 'SPN1_Diff_Solar_N',\n",
    "       'sigma', 'ghi_cc_val', 'dhi_cc_val', 't1_lim', 'flag_clear',\\\n",
    "         'ens', 'domain','station_name', 'ghi_mod', 'Error_rel', 'Kc_GHI_pred', 'Kc_GHI_obs', 'Kc_obs_bias',\n",
    "       'Kc_GHI_pred_improved']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7c1160",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b778859",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nb_LTs = len(np.unique(df_temp.LT))\n",
    "\n",
    "idx_t = 0\n",
    "recursive_calculation_covariance_matrices = True\n",
    "add_noise_in_predictions = False\n",
    "nonlinear_predictions = False\n",
    "predictors_vector = ['Kc_GHI_pred', 'cossza']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8095de19",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''for nb_historical_days in [2,3,4,5,6,7,9,11]:\n",
    "#for nb_historical_days in [12,13,14,15,16,17,19,21]:\n",
    "#for nb_historical_days in [22,23,24,25]:\n",
    "    for t in tqdm(range(len(df_temp))):\n",
    "\n",
    "        hour = df_temp.loc[t,'Time'].hour\n",
    "        minutes = df_temp.loc[t,'Time'].minute\n",
    "        #print(f'Time: {lt_hours}:{lt_minutes:02d} (+{lt})')\n",
    "\n",
    "        timestep_enough_historical = (nb_historical_days*2)*nb_LTs  \n",
    "        \n",
    "        if t >= timestep_enough_historical:\n",
    "            # slice df\n",
    "            df_timestep = df_temp.loc[t-(nb_historical_days*nb_LTs)-(nb_historical_days*nb_LTs*recursive_calculation_covariance_matrices):t,:].copy()\n",
    "        else:\n",
    "            df_timestep = df_temp.loc[t:t+(nb_historical_days*nb_LTs)+(nb_historical_days*nb_LTs*recursive_calculation_covariance_matrices),:].copy()\n",
    "            df_timestep = df_timestep[::-1].reset_index(drop=True)\n",
    "        df_timestep = df_timestep.loc[(df_timestep['Time'].dt.hour == hour) & (df_timestep['Time'].dt.minute == minutes)]\n",
    "        df_timestep = df_timestep.loc[~np.isnan(df_timestep['Kc_GHI_pred'])]\n",
    "        df_timestep = df_timestep.loc[~np.isnan(df_timestep['Kc_obs_bias'])]\n",
    "\n",
    "        if (len(df_timestep) == 0) & (len(df_timestep) <= nb_historical_days + (nb_historical_days*recursive_calculation_covariance_matrices) or (t not in df_timestep.index)):\n",
    "            df_temp.loc[t,'Kc_GHI_pred_improved'] = np.nan  \n",
    "            continue\n",
    "\n",
    "        df_timestep = df_timestep.iloc[-(nb_historical_days+1)-(nb_historical_days*recursive_calculation_covariance_matrices):,:]\n",
    "        df_timestep = df_timestep.reset_index(drop = True)\n",
    "\n",
    "        # define prediction-bias variance matrix\n",
    "        W = np.eye(len(predictors_vector))/1000\n",
    "\n",
    "        # define measurement-bias variance matrix\n",
    "        V = 0.01\n",
    "\n",
    "        # define initial error covariance matrix\n",
    "        Po = np.eye(len(predictors_vector))*5\n",
    "\n",
    "        # define initial predicted bias\n",
    "        xo = np.zeros(len(predictors_vector)).reshape(len(predictors_vector),1)\n",
    "\n",
    "        measurement_GHI = []\n",
    "        old_predicted_GHI = []\n",
    "        improved_GHI = []\n",
    "        ground_truths = []\n",
    "        predicted_coefs = []\n",
    "\n",
    "        for idx_i, i in enumerate(df_timestep.index):\n",
    "            if recursive_calculation_covariance_matrices == True:\n",
    "                # --------------------------------------------\n",
    "                #  Calculate matrices of covariance of errors\n",
    "                # --------------------------------------------\n",
    "                if idx_i > nb_historical_days:\n",
    "                    mean_w = sum(predicted_coefs[-(1+day)] - predicted_coefs[-(2+day)] for day in range(nb_historical_days))/nb_historical_days\n",
    "                    mean_v = sum(measurement_GHI[-(1+day)] - improved_GHI[-(1+day)] for day in range(nb_historical_days))/nb_historical_days\n",
    "\n",
    "                    # old method\n",
    "                    W = np.diag(list((1/(nb_historical_days-1))*sum(((predicted_coefs[-(1+day)] - predicted_coefs[-(2+day)]) - mean_w)**2 for day in range(nb_historical_days)).reshape(len(predictors_vector),)))\n",
    "                    V = (1/(nb_historical_days-1))*sum(((measurement_GHI[-(1+day)] - improved_GHI[-(1+day)]) - mean_v)**2 for day in range(nb_historical_days))\n",
    "\n",
    "                    # # improved method (from Lynch, 2014 - Simplified method to derive the Kalman Filter covariance matrices to predict wind speeds from a NWP model)\n",
    "                    # W = (1/(nb_historical_days-1))*sum(dot(((predicted_coefs[-(1+day)] - predicted_coefs[-(2+day)]) - mean_w),((predicted_coefs[-(1+day)] - predicted_coefs[-(2+day)]) - mean_w).T) for day in range(nb_historical_days))\n",
    "                    # V = (1/(nb_historical_days-1))*sum(dot(((measurement_GHI[-(1+day)] - improved_GHI[-(1+day)]) - mean_v),((measurement_GHI[-(1+day)] - improved_GHI[-(1+day)]) - mean_v).T) for day in range(nb_historical_days))\n",
    "\n",
    "            # ----------------------------\n",
    "            #           Predict\n",
    "            # ----------------------------\n",
    "\n",
    "            if idx_i == 0:\n",
    "                # predicted mean bias\n",
    "                x_pred = np.zeros_like(xo)\n",
    "                if add_noise_in_predictions == True:\n",
    "                    x_pred = xo + np.random.multivariate_normal(mean=[0.5]*len(predictors_vector), cov=W, size=1).reshape(-1,1)\n",
    "                else:\n",
    "                    x_pred = xo\n",
    "\n",
    "                # predicted bias covariance matrix\n",
    "                P = Po + W\n",
    "\n",
    "            else:\n",
    "                # predicted mean bias\n",
    "                if add_noise_in_predictions == True:\n",
    "                    x_pred = x_pred + np.random.multivariate_normal(mean=[0]*len(predictors_vector), cov=W, size=1).reshape(-1,1)\n",
    "                else:\n",
    "                    x_pred = x_pred\n",
    "                #x_pred[1:,0] = 0 # only bias is being tracked, our prediction model doesn't account for the other predictors\n",
    "\n",
    "                # predicted bias covariance matrix\n",
    "                P = P + W\n",
    "\n",
    "            # ----------------------------\n",
    "            #           Update\n",
    "            # ----------------------------\n",
    "\n",
    "            # compute transition matrix based on the current predictors for this timestep\n",
    "            H = [df_timestep.loc[i,predictor] for predictor in predictors_vector[1:]]\n",
    "            H = np.asarray([1] + H).reshape(1, len(predictors_vector))\n",
    "            if nonlinear_predictions == True:\n",
    "                H = [predictor**idx_predictor for idx_predictor, predictor in enumerate(H)]\n",
    "\n",
    "            predicted_coefs.append(x_pred)\n",
    "            improved_GHI.append(dot(H,x_pred))\n",
    "            df_timestep.loc[i,'Kc_GHI_pred_improved'] = improved_GHI[-1][0,0]\n",
    "\n",
    "            # compute residual mean bias and residual bias covariance\n",
    "            if add_noise_in_predictions == True:\n",
    "                new_measurement = df_timestep.loc[i,'Kc_GHI_obs'] + np.random.normal(loc = 0, scale = V)\n",
    "            else:\n",
    "                new_measurement = df_timestep.loc[i,'Kc_GHI_obs']\n",
    "            residual_mean = new_measurement - dot(H,x_pred)\n",
    "            residual_covariance = dot(H, P).dot(H.T) + V\n",
    "\n",
    "            # compute Kalman gain based on the transition matrix and residual covariance\n",
    "            K = dot(P, H.T).dot(inv(residual_covariance)) # from documentation https://filterpy.readthedocs.io/en/latest/index.html#use\n",
    "            K = np.nan_to_num(K, nan = 0)\n",
    "\n",
    "            # update mean bias after incorporating measurements\n",
    "            x_pred = x_pred + dot(K,residual_mean)\n",
    "\n",
    "            # update bias covariance matrix after incorporating measurements\n",
    "            #P = dot(K,H).dot(P) # from https://www.youtube.com/watch?v=W0gai93yhsM\n",
    "            P = np.dot(np.eye(len(predictors_vector)) - dot(K,H),P)\n",
    "\n",
    "            measurement_GHI.append(new_measurement)\n",
    "            old_predicted_GHI.append(df_timestep.loc[i,'Kc_GHI_pred'])\n",
    "            ground_truths.append(df_timestep.loc[i,'Kc_GHI_obs'])\n",
    "\n",
    "        # assign final prediction\n",
    "        df_temp.loc[t,'Kc_GHI_pred_improved'] = improved_GHI[-1][0,0]\n",
    "    # calculate overall error metrics for this group of predictors\n",
    "    df_temp['GHI_pred_improved'] = df_temp['Kc_GHI_pred_improved'] * df_temp['GHI_in']\n",
    "\n",
    "    df_temp = df_temp.loc[~np.isnan(df_temp['GHI_pred_improved'])]\n",
    "    df_temp = df_temp.loc[~np.isnan(df_temp['ghi_obs'])]\n",
    "\n",
    "    rms = mean_squared_error(df_temp['ghi_obs'], df_temp['GHI_pred_improved'], squared=False)\n",
    "    mae = mean_absolute_error(df_temp['ghi_obs'], df_temp['GHI_pred_improved'])\n",
    "    mse = mean_squared_error(df_temp['ghi_obs'], df_temp['GHI_pred_improved'])\n",
    "    mbe = np.mean(df_temp['GHI_pred_improved'] - df_temp['ghi_obs'])\n",
    "\n",
    "    print('\\n\\n**************************')\n",
    "    print(f'{nb_historical_days}')\n",
    "    print(f'- RMS: {rms}')\n",
    "    print(f'- MAE: {mae}')\n",
    "    #print(f'- MSE: {mse}')\n",
    "    print(f'- MBE: {mbe}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b54d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitting(da):\n",
    "\n",
    "    x_new = np.linspace(0.01, 1360, 1000)\n",
    "    x_a=np.array(da['ghi_obs'])\n",
    "    y_a=np.array(da['ghi_mod'])\n",
    "    xaa = x_a[~np.isnan(x_a)]\n",
    "    yaa = y_a[~np.isnan(y_a)]\n",
    "    slope_a, intercept_a, r_value_a, p_value_a, std_err_a = stats.linregress(x_a,y_a)\n",
    "    pearson_corr, pearson_pval = pearsonr(xaa,yaa)\n",
    "    coef, p = kendalltau(xaa,yaa)\n",
    "    #print('Kendall correlation coefficient: %.3f' % coef)\n",
    "    rms = mean_squared_error(xaa, yaa, squared=False)\n",
    "    mae = mean_absolute_error(xaa, yaa)\n",
    "    alpha = 0.01\n",
    "    #if p > alpha:\n",
    "        #print('Samples are uncorrelated (fail to reject H0) p=%.3f' % p)\n",
    "    #else:\n",
    "        #print('Samples are correlated (reject H0) p=%.3f' % p)\n",
    "\n",
    "    #print('Pearsons correlation: %.3f' % pearson_corr)\n",
    "    #print('Pearsons p_value: %.3f' % pearson_pval)\n",
    "    #print('RMS: %.3f' % rms)\n",
    "    #print('MAE: %.3f' % mae)\n",
    "    #print('###########################################')\n",
    "    return (pearson_corr, pearson_pval, slope_a, intercept_a, r_value_a, p_value_a, std_err_a, rms, mae)\n",
    "\n",
    "def fitting_pred(da):\n",
    "\n",
    "    x_new = np.linspace(0.01, 1360, 1000)\n",
    "    x_a=np.array(da['ghi_obs'])\n",
    "    y_a=np.array(da['GHI_pred_improved_fin'])\n",
    "    xaa = x_a[~np.isnan(x_a)]\n",
    "    yaa = y_a[~np.isnan(y_a)]\n",
    "\n",
    "    slope_a, intercept_a, r_value_a, p_value_a, std_err_a = stats.linregress(x_a,y_a)\n",
    "    pearson_corr, pearson_pval = pearsonr(xaa,yaa)\n",
    "    coef, p = kendalltau(xaa,yaa)\n",
    "    #print('Kendall correlation coefficient: %.3f' % coef)\n",
    "    rms = mean_squared_error(xaa, yaa, squared=False)\n",
    "    mae = mean_absolute_error(xaa, yaa)\n",
    "    \n",
    "    alpha = 0.01\n",
    "    #if p > alpha:\n",
    "        #print('Samples are uncorrelated (fail to reject H0) p=%.3f' % p)\n",
    "    #else:\n",
    "        #print('Samples are correlated (reject H0) p=%.3f' % p)\n",
    "\n",
    "    #print('Pearsons correlation: %.3f' % pearson_corr)\n",
    "    #print('RMS: %.3f' % rms)\n",
    "    #print('MAE: %.3f' % mae)\n",
    "    #print('###########################################')\n",
    "    \n",
    "    return (pearson_corr, pearson_pval, slope_a, intercept_a, r_value_a, p_value_a, std_err_a, rms, mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53dfa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_all(res, da_mean):\n",
    "    fig = plt.figure()\n",
    "    gs = fig.add_gridspec(4, 3)\n",
    "\n",
    "    ax00 = fig.add_subplot(gs[0, 0:3])\n",
    "    ax00.plot(da_mean.index,da_mean['ghi_obs'],c='DarkBlue',linewidth=0.5)\n",
    "    ax00.plot(da_mean.index,da_mean['ghi_mod'],c='red',linewidth=0.5)\n",
    "    ax00.plot(da_mean.index,da_mean['GHI_pred_improved_fin'],c='green',linewidth=0.5) \n",
    "    ax00.tick_params(axis='both', which='major', labelsize=5)\n",
    "    ax00.set_ylim(0,1360)\n",
    "    ax00.text(100, 1500, 'Manila Observatory WRF-Solar validation (' + str(res)+' km | initialized 00 UTC previous day)',  fontsize=5)\n",
    "    ax00.text(100, 1100, 'ensmean v obs',  fontsize=5)   \n",
    "    ax00.text( 100, 1200,'WRF RMSE = %0.2f'%fitting(da_mean)[7], fontsize=5, color='red')\n",
    "    ax00.text( 300, 1200,'KF-WRF RMSE = %0.2f'%fitting_pred(da_mean)[7], fontsize=5, color='green')\n",
    "    ax00.legend(['Obs','WRF-' + str(res) + 'km', 'Kalman Filter'], bbox_to_anchor=(1.02, 0.98), prop={'size': 5},loc=2, borderaxespad=0.)\n",
    "    images_dir = 'img/2022_runs'\n",
    "    plt.savefig(f\"{images_dir}/{nb_historical_days}days/all_kf_Manila_ts_\" + str(res) +\"km.png\", dpi=500, frameon=False, facecolor='white', bbox_inches=\"tight\")\n",
    "    \n",
    "    \n",
    "    with open(f'2022_{nb_historical_days}.csv', 'w') as fileObj:\n",
    "        writerObj = csv.writer(fileObj)\n",
    "        writerObj.writerow(['label','pearson_corr', 'rms', 'mae'])\n",
    "        wrf = ('WRF all',fitting(da_mean)[0],fitting(da_mean)[7],fitting(da_mean)[8])\n",
    "        kf = ('KF all',fitting_pred(da_mean)[0],fitting_pred(da_mean)[7],fitting_pred(da_mean)[8])\n",
    "        writerObj.writerow(wrf)\n",
    "        writerObj.writerow(kf) \n",
    "        fileObj.close()\n",
    "\n",
    "\n",
    "############################\n",
    "############################\n",
    "############################\n",
    "def ts_cut(res, da_mean):\n",
    "    da_mean = da_mean.iloc[nb_LTs*nb_historical_days:,:] #\n",
    "\n",
    "    fig = plt.figure()\n",
    "    gs = fig.add_gridspec(4, 3)\n",
    "\n",
    "    ax00 = fig.add_subplot(gs[0, 0:3])\n",
    "    ax00.plot(da_mean.index,da_mean['ghi_obs'],c='DarkBlue',linewidth=0.5)\n",
    "    ax00.plot(da_mean.index,da_mean['ghi_mod'],c='red',linewidth=0.5)\n",
    "    ax00.plot(da_mean.index,da_mean['GHI_pred_improved_fin'],c='green',linewidth=0.5) \n",
    "    ax00.tick_params(axis='both', which='major', labelsize=5)\n",
    "    ax00.set_ylim(0,1360)\n",
    "    ax00.text(nb_LTs*nb_historical_days, 1500, 'Manila Observatory WRF-Solar validation (' + str(res)+' km | initialized 00 UTC previous day)',  fontsize=5)\n",
    "    ax00.text(nb_LTs*nb_historical_days, 1100, 'ensmean v obs',  fontsize=5)\n",
    "    ax00.text( nb_LTs*nb_historical_days, 1200,'WRF RMSE = %0.2f'%fitting(da_mean)[7], fontsize=5, color='red')\n",
    "    ax00.text( nb_LTs*nb_historical_days+200, 1200,'KF-WRF RMSE = %0.2f'%fitting_pred(da_mean)[7], fontsize=5, color='green')\n",
    "    ax00.legend(['Obs','WRF-' + str(res) + 'km', 'Kalman Filter'], bbox_to_anchor=(1.02, 0.98), prop={'size': 5},loc=2, borderaxespad=0.)\n",
    "\n",
    "    images_dir = 'img/2022_runs'\n",
    "    plt.savefig(f\"{images_dir}/{nb_historical_days}days/cut_kf_Manila_ts_\" + str(res) +\"km.png\", dpi=500, frameon=False, facecolor='white', bbox_inches=\"tight\")\n",
    "\n",
    "    with open(f'2022_{nb_historical_days}.csv', 'a') as f_object:\n",
    "        writerObj = csv.writer(f_object)\n",
    "        wrf = ('WRF cut',fitting(da_mean)[0],fitting(da_mean)[7],fitting(da_mean)[8])\n",
    "        kf = ('KF cut',fitting_pred(da_mean)[0],fitting_pred(da_mean)[7],fitting_pred(da_mean)[8])\n",
    "        writerObj.writerow(wrf)\n",
    "        writerObj.writerow(kf)\n",
    "        f_object.close()\n",
    "\n",
    "\n",
    "############################\n",
    "############################\n",
    "############################    \n",
    "def scat_all(res, da_mean):   \n",
    "    plt_da = da_mean\n",
    "    x_new = np.linspace(0.01, 1360, 1000)\n",
    "    fig = plt.figure()\n",
    "    gs = fig.add_gridspec(4, 15)\n",
    "    \n",
    "    ax00 = fig.add_subplot(gs[0:1, 0:3])   \n",
    "    ax00.scatter(x=plt_da['ghi_obs'],y=plt_da['ghi_mod'],c='red',s=0.1,alpha=0.5)\n",
    "    plt.plot(x_new,x_new,c='gray',linewidth=0.1)\n",
    "    ax00.text( 50, 1000,'RMSE = %0.2f'%fitting(plt_da)[7], fontsize=3, color='red')\n",
    "    ax00.text( 50, 1100,'R* = %0.2f'%fitting(plt_da)[0], fontsize=3, color='red')\n",
    "    ax00.text( 200, 1390,'WRF-Solar '+ str(res) + '-km', fontsize=5, color='red')\n",
    "    ax00.tick_params(axis='both', which='major', labelsize=5)\n",
    "    ax00.set_ylim(0,1360)\n",
    "    ax00.set_xlim(0,1360)\n",
    "    ax00.set_ylabel('Model\\nGHI (W/m$^2$)',  fontsize=5)\n",
    "    \n",
    "    ax00 = fig.add_subplot(gs[0:1, 4:7])\n",
    "    ax00.scatter(x=plt_da['ghi_obs'],y=plt_da['GHI_pred_improved_fin'],c='green',s=0.1,alpha=0.5)\n",
    "    plt.plot(x_new,x_new,c='gray',linewidth=0.1)\n",
    "    ax00.tick_params(axis='both', which='major', labelsize=5)\n",
    "    ax00.text( 50, 1100,'R* = %0.2f'%fitting_pred(plt_da)[0], fontsize=3, color='green')\n",
    "    ax00.text( 50, 1000,'RMSE = %0.2f'%fitting_pred(plt_da)[7], fontsize=3, color='green')\n",
    "    ax00.text( 200, 1390,'KF WRF-Solar '+ str(res) + '-km', fontsize=5, color='green')\n",
    "    ax00.set_ylim(0,1360)\n",
    "    ax00.set_xlim(0,1360)\n",
    "    ax00.text( -500, -800,'Observed\\nGHI (W/m$^2$)', fontsize=5, color='k')\n",
    "    \n",
    "    images_dir = 'img/2022_runs'\n",
    "    plt.savefig(f\"{images_dir}/{nb_historical_days}days/all_kf_Manila_scatplot_\" + str((res)) + \"km.png\", dpi=500, frameon=False, facecolor='white', bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "############################\n",
    "############################\n",
    "############################ \n",
    "def scat_cut(res, da_mean):   \n",
    "    x_new = np.linspace(0.01, 1360, 1000)\n",
    "    plt_da = da_mean.iloc[nb_LTs*nb_historical_days:,:] #\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    gs = fig.add_gridspec(4, 15) \n",
    "    \n",
    "    ax00 = fig.add_subplot(gs[0:1, 0:3])\n",
    "    ax00.scatter(x=plt_da['ghi_obs'],y=plt_da['ghi_mod'],c='red',s=0.1,alpha=0.5)\n",
    "    plt.plot(x_new,x_new,c='gray',linewidth=0.1)\n",
    "    ax00.text( 50, 1000,'RMSE = %0.2f'%fitting(plt_da)[7], fontsize=3, color='red')\n",
    "    ax00.text( 50, 1100,'R* = %0.2f'%fitting(plt_da)[0], fontsize=3, color='red')\n",
    "    ax00.text( 200, 1390,'WRF-Solar '+ str(res) + '-km', fontsize=5, color='red')\n",
    "    ax00.tick_params(axis='both', which='major', labelsize=5)\n",
    "    ax00.set_ylim(0,1360)\n",
    "    ax00.set_xlim(0,1360)\n",
    "    ax00.set_ylabel('Model\\nGHI (W/m$^2$)',  fontsize=5)   \n",
    "    \n",
    "    ax00 = fig.add_subplot(gs[0:1, 4:7])\n",
    "    ax00.scatter(x=plt_da['ghi_obs'],y=plt_da['GHI_pred_improved_fin'],c='green',s=0.1,alpha=0.5)\n",
    "    plt.plot(x_new,x_new,c='gray',linewidth=0.1)\n",
    "    ax00.tick_params(axis='both', which='major', labelsize=5)\n",
    "    ax00.text( 50, 1100,'R* = %0.2f'%fitting_pred(plt_da)[0], fontsize=3, color='green')\n",
    "    ax00.text( 50, 1000,'RMSE = %0.2f'%fitting_pred(plt_da)[7], fontsize=3, color='green')\n",
    "    ax00.text( 200, 1390,'KF WRF-Solar '+ str(res) + '-km', fontsize=5, color='green')\n",
    "    ax00.set_ylim(0,1360)\n",
    "    ax00.set_xlim(0,1360)\n",
    "    ax00.text( -500, -800,'Observed\\nGHI (W/m$^2$)', fontsize=5, color='k')\n",
    "    \n",
    "    images_dir = 'img/2022_runs'\n",
    "    plt.savefig(f\"{images_dir}/{nb_historical_days}days/cut_kf_Manila_scatplot_\" + str((res)) + \"km.png\", dpi=500, frameon=False, facecolor='white', bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "############################\n",
    "############################\n",
    "############################ \n",
    "\n",
    "def scat_cloudy_all(res, da_mean):\n",
    "    x_new = np.linspace(0.01, 1360, 1000)\n",
    "    plt_da = da_mean\n",
    "    plt_da = plt_da[plt_da['flag_clear'] == 'N']\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    gs = fig.add_gridspec(4, 15)\n",
    "    \n",
    "    ax00 = fig.add_subplot(gs[0:1, 0:3])    \n",
    "    ax00.scatter(x=plt_da['ghi_obs'],y=plt_da['ghi_mod'],c='red',s=0.1,alpha=0.5)\n",
    "    plt.plot(x_new,x_new,c='gray',linewidth=0.1)\n",
    "    ax00.text( 50, 1000,'RMSE = %0.2f'%fitting(plt_da)[7], fontsize=3, color='red')\n",
    "    ax00.text( 50, 1100,'R* = %0.2f'%fitting(plt_da)[0], fontsize=3, color='red')\n",
    "    ax00.text( 200, 1390,'WRF-Solar '+ str(res) + '-km', fontsize=5, color='red')\n",
    "    ax00.tick_params(axis='both', which='major', labelsize=5)\n",
    "    ax00.set_ylim(0,1360)\n",
    "    ax00.set_xlim(0,1360)\n",
    "    ax00.set_ylabel('Model\\nGHI (W/m$^2$)',  fontsize=5)\n",
    "        \n",
    "    ax00 = fig.add_subplot(gs[0:1, 4:7])\n",
    "    ax00.scatter(x=plt_da['ghi_obs'],y=plt_da['GHI_pred_improved_fin'],c='green',s=0.1,alpha=0.5)\n",
    "    plt.plot(x_new,x_new,c='gray',linewidth=0.1)\n",
    "    ax00.tick_params(axis='both', which='major', labelsize=5)\n",
    "    ax00.text( 50, 1100,'R* = %0.2f'%fitting_pred(plt_da)[0], fontsize=3, color='green')\n",
    "    ax00.text( 50, 1000,'RMSE = %0.2f'%fitting_pred(plt_da)[7], fontsize=3, color='green')\n",
    "    ax00.text( 200, 1390,'KF WRF-Solar '+ str(res) + '-km', fontsize=5, color='green')\n",
    "    ax00.set_ylim(0,1360)\n",
    "    ax00.set_xlim(0,1360)\n",
    "    ax00.text( -500, -800,'Observed\\nGHI (W/m$^2$)', fontsize=5, color='k')\n",
    "    ax00.text( -800, 1600,'Cloudy Periods', fontsize=5, color='k')\n",
    "    \n",
    "    images_dir = 'img/2022_runs'\n",
    "    plt.savefig(f\"{images_dir}/{nb_historical_days}days/all_cloudy_kf_Manila_scatplot_\" + str((res)) + \"km.png\", dpi=500, frameon=False, facecolor='white', bbox_inches=\"tight\")\n",
    "    \n",
    "    with open(f'2022_{nb_historical_days}.csv', 'a') as f_object:\n",
    "        writerObj = csv.writer(f_object)\n",
    "        wrf = ('WRF cloudy all',fitting(plt_da)[0],fitting(plt_da)[7],fitting(plt_da)[8])\n",
    "        kf = ('KF cloudy all',fitting_pred(plt_da)[0],fitting_pred(plt_da)[7],fitting_pred(plt_da)[8])\n",
    "        writerObj.writerow(wrf)\n",
    "        writerObj.writerow(kf)\n",
    "        f_object.close()\n",
    "        \n",
    "############################\n",
    "############################\n",
    "############################ \n",
    "def scat_cloudy_cut(res, da_mean):\n",
    "\n",
    "    x_new = np.linspace(0.01, 1360, 1000)\n",
    "    plt_da = da_mean.iloc[nb_LTs*nb_historical_days:,:] #\n",
    "    plt_da = plt_da[plt_da['flag_clear'] == 'N']\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    gs = fig.add_gridspec(4, 15)\n",
    "    \n",
    "    ax00 = fig.add_subplot(gs[0:1, 0:3])\n",
    "    ax00.scatter(x=plt_da['ghi_obs'],y=plt_da['ghi_mod'],c='red',s=0.1,alpha=0.5)\n",
    "    plt.plot(x_new,x_new,c='gray',linewidth=0.1)\n",
    "    ax00.text( 50, 1000,'RMSE = %0.2f'%fitting(plt_da)[7], fontsize=3, color='red')\n",
    "    ax00.text( 50, 1100,'R* = %0.2f'%fitting(plt_da)[0], fontsize=3, color='red')\n",
    "    ax00.text( 200, 1390,'WRF-Solar '+ str(res) + '-km', fontsize=5, color='red')\n",
    "    ax00.tick_params(axis='both', which='major', labelsize=5)\n",
    "    ax00.set_ylim(0,1360)\n",
    "    ax00.set_xlim(0,1360)\n",
    "    ax00.set_ylabel('Model\\nGHI (W/m$^2$)',  fontsize=5)\n",
    "    \n",
    "    ax00 = fig.add_subplot(gs[0:1, 4:7])\n",
    "    ax00.scatter(x=plt_da['ghi_obs'],y=plt_da['GHI_pred_improved_fin'],c='green',s=0.1,alpha=0.5)\n",
    "    plt.plot(x_new,x_new,c='gray',linewidth=0.1)\n",
    "    ax00.tick_params(axis='both', which='major', labelsize=5)\n",
    "    ax00.text( 50, 1100,'R* = %0.2f'%fitting_pred(plt_da)[0], fontsize=3, color='green')\n",
    "    ax00.text( 50, 1000,'RMSE = %0.2f'%fitting_pred(plt_da)[7], fontsize=3, color='green')\n",
    "    ax00.text( 200, 1390,'KF WRF-Solar '+ str(res) + '-km', fontsize=5, color='green')\n",
    "    ax00.set_ylim(0,1360)\n",
    "    ax00.set_xlim(0,1360)\n",
    "    ax00.text( -500, -800,'Observed\\nGHI (W/m$^2$)', fontsize=5, color='k')\n",
    "    ax00.text( -800, 1600,'Cloudy Periods', fontsize=5, color='k')\n",
    "    \n",
    "    images_dir = 'img/2022_runs'\n",
    "    plt.savefig(f\"{images_dir}/{nb_historical_days}days/cut_cloudy_kf_Manila_scatplot_\" + str((res)) + \"km.png\", dpi=500, frameon=False, facecolor='white', bbox_inches=\"tight\")\n",
    "    \n",
    "    with open(f'2022_{nb_historical_days}.csv', 'a') as f_object:\n",
    "        writerObj = csv.writer(f_object)\n",
    "        wrf = ('WRF cloudy cut',fitting(plt_da)[0],fitting(plt_da)[7],fitting(plt_da)[8])\n",
    "        kf = ('KF cloudy cut',fitting_pred(plt_da)[0],fitting_pred(plt_da)[7],fitting_pred(plt_da)[8])\n",
    "        writerObj.writerow(wrf)\n",
    "        writerObj.writerow(kf)\n",
    "        f_object.close()\n",
    "############################\n",
    "############################\n",
    "############################         \n",
    "def scat_clear_all(res, da_mean):\n",
    "\n",
    "    x_new = np.linspace(0.01, 1360, 1000)\n",
    "    plt_da = da_mean\n",
    "    plt_da = plt_da[plt_da['flag_clear'] == 'Y']\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    gs = fig.add_gridspec(4, 15)\n",
    "    \n",
    "    ax00 = fig.add_subplot(gs[0:1, 0:3])\n",
    "    ax00.scatter(x=plt_da['ghi_obs'],y=plt_da['ghi_mod'],c='red',s=0.1,alpha=0.5)\n",
    "    plt.plot(x_new,x_new,c='gray',linewidth=0.1)\n",
    "    ax00.text( 50, 1000,'RMSE = %0.2f'%fitting(plt_da)[7], fontsize=3, color='red')\n",
    "    ax00.text( 50, 1100,'R* = %0.2f'%fitting(plt_da)[0], fontsize=3, color='red')\n",
    "    ax00.text( 200, 1390,'WRF-Solar '+ str(res) + '-km', fontsize=5, color='red')\n",
    "    ax00.tick_params(axis='both', which='major', labelsize=5)\n",
    "    ax00.set_ylim(0,1360)\n",
    "    ax00.set_xlim(0,1360)\n",
    "    ax00.set_ylabel('Model\\nGHI (W/m$^2$)',  fontsize=5) \n",
    "    \n",
    "    ax00 = fig.add_subplot(gs[0:1, 4:7])\n",
    "    ax00.scatter(x=plt_da['ghi_obs'],y=plt_da['GHI_pred_improved_fin'],c='green',s=0.1,alpha=0.5)\n",
    "    plt.plot(x_new,x_new,c='gray',linewidth=0.1)\n",
    "    ax00.tick_params(axis='both', which='major', labelsize=5)\n",
    "    ax00.text( 50, 1100,'R* = %0.2f'%fitting_pred(plt_da)[0], fontsize=3, color='green')\n",
    "    ax00.text( 50, 1000,'RMSE = %0.2f'%fitting_pred(plt_da)[7], fontsize=3, color='green')\n",
    "    ax00.text( 200, 1390,'KF WRF-Solar '+ str(res) + '-km', fontsize=5, color='green')\n",
    "    ax00.set_ylim(0,1360)\n",
    "    ax00.set_xlim(0,1360)\n",
    "    ax00.text( -500, -800,'Observed\\nGHI (W/m$^2$)', fontsize=5, color='k')\n",
    "    ax00.text( -800, 1600,'Clear Sky Periods', fontsize=5, color='k')\n",
    "    \n",
    "    images_dir = 'img/2022_runs'\n",
    "    plt.savefig(f\"{images_dir}/{nb_historical_days}days/all_clear_kf_Manila_scatplot_\" + str((res)) + \"km.png\", dpi=500, frameon=False, facecolor='white', bbox_inches=\"tight\")\n",
    "   \n",
    "    with open(f'2022_{nb_historical_days}.csv', 'a') as f_object:\n",
    "        writerObj = csv.writer(f_object)\n",
    "        wrf = ('WRF clear all',fitting(plt_da)[0],fitting(plt_da)[7],fitting(plt_da)[8])\n",
    "        kf = ('KF clear all',fitting_pred(plt_da)[0],fitting_pred(plt_da)[7],fitting_pred(plt_da)[8])\n",
    "        writerObj.writerow(wrf)\n",
    "        writerObj.writerow(kf)\n",
    "        f_object.close()\n",
    "############################\n",
    "############################\n",
    "############################ \n",
    "def scat_clear_cut(res, da_mean):\n",
    "    x_new = np.linspace(0.01, 1360, 1000)\n",
    "    plt_da = da_mean.iloc[nb_LTs*nb_historical_days:,:] #\n",
    "    plt_da = plt_da[plt_da['flag_clear'] == 'Y']\n",
    "    fig = plt.figure()\n",
    "    gs = fig.add_gridspec(4, 15)\n",
    "    \n",
    "    ax00 = fig.add_subplot(gs[0:1, 0:3])\n",
    "    ax00.scatter(x=plt_da['ghi_obs'],y=plt_da['ghi_mod'],c='red',s=0.1,alpha=0.5)\n",
    "    plt.plot(x_new,x_new,c='gray',linewidth=0.1)\n",
    "    ax00.text( 50, 1000,'RMSE = %0.2f'%fitting(plt_da)[7], fontsize=3, color='red')\n",
    "    ax00.text( 50, 1100,'R* = %0.2f'%fitting(plt_da)[0], fontsize=3, color='red')\n",
    "    ax00.text( 200, 1390,'WRF-Solar '+ str(res) + '-km', fontsize=5, color='red')\n",
    "    ax00.tick_params(axis='both', which='major', labelsize=5)\n",
    "    ax00.set_ylim(0,1360)\n",
    "    ax00.set_xlim(0,1360)\n",
    "    ax00.set_ylabel('Model\\nGHI (W/m$^2$)',  fontsize=5)\n",
    "    \n",
    "    ax00 = fig.add_subplot(gs[0:1, 4:7])\n",
    "    ax00.scatter(x=plt_da['ghi_obs'],y=plt_da['GHI_pred_improved_fin'],c='green',s=0.1,alpha=0.5)\n",
    "    plt.plot(x_new,x_new,c='gray',linewidth=0.1)\n",
    "    ax00.tick_params(axis='both', which='major', labelsize=5)\n",
    "    ax00.text( 50, 1100,'R* = %0.2f'%fitting_pred(plt_da)[0], fontsize=3, color='green')\n",
    "    ax00.text( 50, 1000,'RMSE = %0.2f'%fitting_pred(plt_da)[7], fontsize=3, color='green')\n",
    "    ax00.text( 200, 1390,'KF WRF-Solar '+ str(res) + '-km', fontsize=5, color='green')\n",
    "    ax00.set_ylim(0,1360)\n",
    "    ax00.set_xlim(0,1360)\n",
    "    ax00.text( -500, -800,'Observed\\nGHI (W/m$^2$)', fontsize=5, color='k')\n",
    "    ax00.text( -800, 1600,'Clear Sky Periods', fontsize=5, color='k')\n",
    "    \n",
    "    images_dir = 'img/2022_runs'\n",
    "    plt.savefig(f\"{images_dir}/{nb_historical_days}days/cut_clear_kf_Manila_scatplot_\" + str((res)) + \"km.png\", dpi=500, frameon=False, facecolor='white', bbox_inches=\"tight\")\n",
    "   \n",
    "    with open(f'2022_{nb_historical_days}.csv', 'a') as f_object:\n",
    "        writerObj = csv.writer(f_object)\n",
    "        wrf = ('WRF clear cut',fitting(plt_da)[0],fitting(plt_da)[7],fitting(plt_da)[8])\n",
    "        kf = ('KF clear cut',fitting_pred(plt_da)[0],fitting_pred(plt_da)[7],fitting_pred(plt_da)[8])\n",
    "        writerObj.writerow(wrf)\n",
    "        writerObj.writerow(kf)\n",
    "        f_object.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad7725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for nb_historical_days in [4,6]:\n",
    "    #nb_historical_days = 11\n",
    "    timestep_enough_historical = (nb_historical_days*2)*nb_LTs  \n",
    "    for t in tqdm(range(len(df_temp))):\n",
    "\n",
    "        hour = df_temp.loc[t,'Time'].hour\n",
    "        minutes = df_temp.loc[t,'Time'].minute\n",
    "        #print(f'Time: {lt_hours}:{lt_minutes:02d} (+{lt})')\n",
    "\n",
    "\n",
    "        if t >= timestep_enough_historical:\n",
    "            # slice df\n",
    "            df_timestep = df_temp.loc[t-(nb_historical_days*nb_LTs)-(nb_historical_days*nb_LTs*recursive_calculation_covariance_matrices):t,:].copy()\n",
    "        else:\n",
    "            df_timestep = df_temp.loc[t:t+(nb_historical_days*nb_LTs)+(nb_historical_days*nb_LTs*recursive_calculation_covariance_matrices),:].copy()\n",
    "            df_timestep = df_timestep[::-1].reset_index(drop=True)\n",
    "        df_timestep = df_timestep.loc[(df_timestep['Time'].dt.hour == hour) & (df_timestep['Time'].dt.minute == minutes)]\n",
    "        df_timestep = df_timestep.loc[~np.isnan(df_timestep['Kc_GHI_pred'])]\n",
    "        df_timestep = df_timestep.loc[~np.isnan(df_timestep['Kc_obs_bias'])]\n",
    "\n",
    "        if (len(df_timestep) == 0) & (len(df_timestep) <= nb_historical_days + (nb_historical_days*recursive_calculation_covariance_matrices) or (t not in df_timestep.index)):\n",
    "            df_temp.loc[t,'Kc_GHI_pred_improved'] = np.nan  \n",
    "            continue\n",
    "\n",
    "        df_timestep = df_timestep.iloc[-(nb_historical_days+1)-(nb_historical_days*recursive_calculation_covariance_matrices):,:]\n",
    "        df_timestep = df_timestep.reset_index(drop = True)\n",
    "\n",
    "        # define prediction-bias variance matrix\n",
    "        W = np.eye(len(predictors_vector))/1000\n",
    "\n",
    "        # define measurement-bias variance matrix\n",
    "        V = 0.01\n",
    "\n",
    "        # define initial error covariance matrix\n",
    "        Po = np.eye(len(predictors_vector))*5\n",
    "\n",
    "        # define initial predicted bias\n",
    "        xo = np.zeros(len(predictors_vector)).reshape(len(predictors_vector),1)\n",
    "\n",
    "        measurement_GHI = []\n",
    "        old_predicted_GHI = []\n",
    "        improved_GHI = []\n",
    "        ground_truths = []\n",
    "        predicted_coefs = []\n",
    "\n",
    "        for idx_i, i in enumerate(df_timestep.index):\n",
    "            if recursive_calculation_covariance_matrices == True:\n",
    "                # --------------------------------------------\n",
    "                #  Calculate matrices of covariance of errors\n",
    "                # --------------------------------------------\n",
    "                if idx_i > nb_historical_days:\n",
    "                    mean_w = sum(predicted_coefs[-(1+day)] - predicted_coefs[-(2+day)] for day in range(nb_historical_days))/nb_historical_days\n",
    "                    mean_v = sum(measurement_GHI[-(1+day)] - improved_GHI[-(1+day)] for day in range(nb_historical_days))/nb_historical_days\n",
    "\n",
    "                    # old method\n",
    "                    W = np.diag(list((1/(nb_historical_days-1))*sum(((predicted_coefs[-(1+day)] - predicted_coefs[-(2+day)]) - mean_w)**2 for day in range(nb_historical_days)).reshape(len(predictors_vector),)))\n",
    "                    V = (1/(nb_historical_days-1))*sum(((measurement_GHI[-(1+day)] - improved_GHI[-(1+day)]) - mean_v)**2 for day in range(nb_historical_days))\n",
    "\n",
    "                    # # improved method (from Lynch, 2014 - Simplified method to derive the Kalman Filter covariance matrices to predict wind speeds from a NWP model)\n",
    "                    # W = (1/(nb_historical_days-1))*sum(dot(((predicted_coefs[-(1+day)] - predicted_coefs[-(2+day)]) - mean_w),((predicted_coefs[-(1+day)] - predicted_coefs[-(2+day)]) - mean_w).T) for day in range(nb_historical_days))\n",
    "                    # V = (1/(nb_historical_days-1))*sum(dot(((measurement_GHI[-(1+day)] - improved_GHI[-(1+day)]) - mean_v),((measurement_GHI[-(1+day)] - improved_GHI[-(1+day)]) - mean_v).T) for day in range(nb_historical_days))\n",
    "\n",
    "            # ----------------------------\n",
    "            #           Predict\n",
    "            # ----------------------------\n",
    "\n",
    "            if idx_i == 0:\n",
    "                # predicted mean bias\n",
    "                x_pred = np.zeros_like(xo)\n",
    "                if add_noise_in_predictions == True:\n",
    "                    x_pred = xo + np.random.multivariate_normal(mean=[0.5]*len(predictors_vector), cov=W, size=1).reshape(-1,1)\n",
    "                else:\n",
    "                    x_pred = xo\n",
    "\n",
    "                # predicted bias covariance matrix\n",
    "                P = Po + W\n",
    "\n",
    "            else:\n",
    "                # predicted mean bias\n",
    "                if add_noise_in_predictions == True:\n",
    "                    x_pred = x_pred + np.random.multivariate_normal(mean=[0]*len(predictors_vector), cov=W, size=1).reshape(-1,1)\n",
    "                else:\n",
    "                    x_pred = x_pred\n",
    "                #x_pred[1:,0] = 0 # only bias is being tracked, our prediction model doesn't account for the other predictors\n",
    "\n",
    "                # predicted bias covariance matrix\n",
    "                P = P + W\n",
    "\n",
    "            # ----------------------------\n",
    "            #           Update\n",
    "            # ----------------------------\n",
    "\n",
    "            # compute transition matrix based on the current predictors for this timestep\n",
    "            H = [df_timestep.loc[i,predictor] for predictor in predictors_vector[1:]]\n",
    "            H = np.asarray([1] + H).reshape(1, len(predictors_vector))\n",
    "            if nonlinear_predictions == True:\n",
    "                H = [predictor**idx_predictor for idx_predictor, predictor in enumerate(H)]\n",
    "\n",
    "            predicted_coefs.append(x_pred)\n",
    "            improved_GHI.append(dot(H,x_pred))\n",
    "            df_timestep.loc[i,'Kc_GHI_pred_improved'] = improved_GHI[-1][0,0]\n",
    "\n",
    "            # compute residual mean bias and residual bias covariance\n",
    "            if add_noise_in_predictions == True:\n",
    "                new_measurement = df_timestep.loc[i,'Kc_GHI_obs'] + np.random.normal(loc = 0, scale = V)\n",
    "            else:\n",
    "                new_measurement = df_timestep.loc[i,'Kc_GHI_obs']\n",
    "            residual_mean = new_measurement - dot(H,x_pred)\n",
    "            residual_covariance = dot(H, P).dot(H.T) + V\n",
    "\n",
    "            # compute Kalman gain based on the transition matrix and residual covariance\n",
    "            K = dot(P, H.T).dot(inv(residual_covariance)) # from documentation https://filterpy.readthedocs.io/en/latest/index.html#use\n",
    "            K = np.nan_to_num(K, nan = 0)\n",
    "\n",
    "            # update mean bias after incorporating measurements\n",
    "            x_pred = x_pred + dot(K,residual_mean)\n",
    "\n",
    "            # update bias covariance matrix after incorporating measurements\n",
    "            #P = dot(K,H).dot(P) # from https://www.youtube.com/watch?v=W0gai93yhsM\n",
    "            P = np.dot(np.eye(len(predictors_vector)) - dot(K,H),P)\n",
    "\n",
    "            measurement_GHI.append(new_measurement)\n",
    "            old_predicted_GHI.append(df_timestep.loc[i,'Kc_GHI_pred'])\n",
    "            ground_truths.append(df_timestep.loc[i,'Kc_GHI_obs'])\n",
    "\n",
    "        # assign final prediction\n",
    "        df_temp.loc[t,'Kc_GHI_pred_improved'] = improved_GHI[-1][0,0]\n",
    "    # calculate overall error metrics for this group of predictors\n",
    "    df_temp['GHI_pred_improved'] = df_temp['Kc_GHI_pred_improved'] * df_temp['GHI_in']\n",
    "\n",
    "    df_temp = df_temp.loc[~np.isnan(df_temp['GHI_pred_improved'])]\n",
    "    df_temp = df_temp.loc[~np.isnan(df_temp['ghi_obs'])]\n",
    "\n",
    "    rms = mean_squared_error(df_temp['ghi_obs'], df_temp['GHI_pred_improved'], squared=False)\n",
    "    mae = mean_absolute_error(df_temp['ghi_obs'], df_temp['GHI_pred_improved'])\n",
    "    mse = mean_squared_error(df_temp['ghi_obs'], df_temp['GHI_pred_improved'])\n",
    "    mbe = np.mean(df_temp['GHI_pred_improved'] - df_temp['ghi_obs'])\n",
    "\n",
    "    print('\\n\\n**************************')\n",
    "    print(f'Predictors: {predictors_vector}')\n",
    "    print(f'- RMS: {rms}')\n",
    "    print(f'- MAE: {mae}')\n",
    "    #print(f'- MSE: {mse}')\n",
    "    print(f'- MBE: {mbe}')\n",
    "\n",
    "    # assign post-processed timesteps to original dataframe\n",
    "    copy = df_temp[['Time','GHI_pred_improved']]\n",
    "\n",
    "\n",
    "    df_updated = df.merge(copy,how='outer',on=\"Time\")\n",
    "    df_updated['kf_obs'] = np.abs(df_updated['GHI_pred_improved'] - df_updated['ghi_obs'])\n",
    "    df_updated['wrf_obs'] = np.abs(df_updated['ghi_mod'] - df_updated['ghi_obs'])\n",
    "    #recording HITs and MISS for each LT or time of the day (Contingency Table)\n",
    "    def lim(df):\n",
    "        if ((df['GHI_pred_improved'] >= 0) & (df['kf_obs'] <= df['wrf_obs'])):\n",
    "            lim = 'HIT' #by KF\n",
    "        else:\n",
    "            lim = 'MISS'\n",
    "        return(lim)\n",
    "\n",
    "    df_updated[\"flag_hit\"] = df_updated.apply(lim, axis=1)\n",
    "\n",
    "    table = df_updated.groupby(['LT','flag_hit']).agg({'flag_hit': ['count']}).droplevel(axis=1, level=0).reset_index()#.to_csv('summary.csv')\n",
    "    table = pd.pivot_table(table, values='count', index=['LT'],columns=['flag_hit']).reset_index()#.to_csv('summary.csv')\n",
    "\n",
    "    #this will be used to know whether the WRF or KF output is better for each LT or time of the day\n",
    "    def hit(t):\n",
    "        if ((t['HIT'] >= 0) & (t['HIT'] >= t['MISS'])):\n",
    "            hit = 'KF'\n",
    "        else:\n",
    "            hit = 'WRF'\n",
    "        return(hit)\n",
    "    table[\"final\"] = table.apply(hit, axis=1)\n",
    "\n",
    "    df_updated = df_updated.merge(table,how='outer',on=\"LT\")\n",
    "    #depending on contingency table for each LT or time of the day \n",
    "    #use KF or WRF output\n",
    "    def final_pred(df):\n",
    "        if ((df['GHI_pred_improved'] >= 0) & (df['final'] == 'KF')):\n",
    "            lim = df['GHI_pred_improved']\n",
    "        else:\n",
    "            lim = df['ghi_mod']\n",
    "        return(lim)\n",
    "\n",
    "    df_updated[\"GHI_pred_improved_fin\"] = df_updated.apply(final_pred, axis=1)\n",
    "    df_updated = df_updated.sort_values(by='Time').reset_index()\n",
    "    #example for nb_historical_days=4\n",
    "    #we are only correcting for 29 while 48 points are retained\n",
    "    df_updated = df_updated[['Time',  'CMP22_Total_Solar', 'SPN1_Total_Solar',\n",
    "           'SPN1_Diff_Solar', 'CGR4_IR', 'dhi', 'ghi_a', 'sza', 'cossza', 'dni',\n",
    "           'MM', 'DD', 'HH', 'mm', 'GHI_in', 'DNI_in', 'DHI_in', 'cossza_b',\n",
    "           'SPN1_Total_Solar_N', 't2_lim', 'cossza_noon', 'FT_t', 'FT_TOA',\n",
    "           'FT_TOA_t', 't3_llim', 't3_ulim', 'Diffuse_Ratio', 'SPN1_Diff_Solar_N',\n",
    "           'sigma', 'ghi_cc_val', 'dhi_cc_val', 't1_lim', 'flag_clear', 'ghi_obs',\n",
    "           'ens', 'domain', 'station_name', 'variable', 'ghi_mod', 'YY',\n",
    "           'Error_rel', 'Kc_GHI_pred', 'Kc_GHI_obs', 'Kc_obs_bias', 'LT',\n",
    "           'GHI_pred_improved_fin']]\n",
    "    # calculate overall error metrics for this group of predictors\n",
    "    df_updated = df_updated.loc[~np.isnan(df_updated['GHI_pred_improved_fin'])]\n",
    "    df_updated = df_updated.loc[~np.isnan(df_updated['ghi_obs'])]\n",
    "\n",
    "    rms = mean_squared_error(df_updated['ghi_obs'], df_updated['GHI_pred_improved_fin'], squared=False)\n",
    "    mae = mean_absolute_error(df_updated['ghi_obs'], df_updated['GHI_pred_improved_fin'])\n",
    "    mse = mean_squared_error(df_updated['ghi_obs'], df_updated['GHI_pred_improved_fin'])\n",
    "    mbe = np.mean(df_updated['GHI_pred_improved_fin'] - df_updated['ghi_obs'])\n",
    "\n",
    "    '''print('\\n\\n**************************')\n",
    "    print(f'Predictors: {predictors_vector}')\n",
    "    print(f'- RMS: {rms}')\n",
    "    print(f'- MAE: {mae}')\n",
    "    #print(f'- MSE: {mse}')\n",
    "    print(f'- MBE: {mbe}')'''\n",
    "\n",
    "\n",
    "    scat_all(5, df_updated)\n",
    "    scat_cut(5, df_updated)\n",
    "    scat_cloudy_all(5, df_updated)\n",
    "    scat_cloudy_cut(5, df_updated)\n",
    "    scat_clear_all(5, df_updated)\n",
    "    scat_clear_cut(5, df_updated)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
